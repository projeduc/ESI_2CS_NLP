@inproceedings{2019-oufaida-al,
	author    = {Houda Oufaida and
	Philippe Blache and
	Omar Nouali},
	editor    = {Elisabeth M{\'{e}}tais and
	Farid Meziane and
	Sunil Vadera and
	Vijayan Sugumaran and
	Mohamad Saraee},
	title     = {A Coherence Model for Sentence Ordering},
	booktitle = {Natural Language Processing and Information Systems - 24th International
	Conference on Applications of Natural Language to Information Systems,
	{NLDB} 2019, Salford, UK, June 26-28, 2019, Proceedings},
	series    = {Lecture Notes in Computer Science},
	volume    = {11608},
	pages     = {261--273},
	publisher = {Springer},
	year      = {2019},
	url       = {https://doi.org/10.1007/978-3-030-23281-8\_21},
	doi       = {10.1007/978-3-030-23281-8\_21},
	timestamp = {Tue, 25 Jun 2019 12:32:07 +0200},
	biburl    = {https://dblp.org/rec/conf/nldb/OufaidaBN19.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{2011-recasens-hovy,
	author = {Recasens, M. and Hovy, E.},
	title = {Blanc: Implementing the Rand Index for Coreference Evaluation},
	year = {2011},
	issue_date = {October 2011},
	publisher = {Cambridge University Press},
	address = {USA},
	volume = {17},
	number = {4},
	issn = {1351-3249},
	url = {https://doi.org/10.1017/S135132491000029X},
	doi = {10.1017/S135132491000029X},
	abstract = {This paper addresses the current state of coreference resolution evaluation, in which
	different measures (notably, MUC, B3, CEAF, and ACE-value) are applied in different
	studies. None of them is fully adequate, and their measures are not commensurate.
	We enumerate the desiderata for a coreference scoring measure, discuss the strong
	and weak points of the existing measures, and propose the BiLateral Assessment of
	Noun-Phrase Coreference, a variation of the Rand index created to suit the coreference
	task. The BiLateral Assessment of Noun-Phrase Coreference rewards both coreference
	and non-coreference links by averaging the F-scores of the two types, does not ignore
	singletons-the main problem with the MUC score-and does not inflate the score in their
	presence-a problem with the B3 and CEAF scores. In addition, its fine granularity
	is consistent over the whole range of scores and affords better discrimination between
	systems.},
	journal = {Nat. Lang. Eng.},
	month = oct,
	pages = {485–510},
	numpages = {26}
}

@inproceedings{2017-dozat-manning,
	author    = {Timothy Dozat and
	Christopher D. Manning},
	title     = {Deep Biaffine Attention for Neural Dependency Parsing},
	booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
	Toulon, France, April 24-26, 2017, Conference Track Proceedings},
	publisher = {OpenReview.net},
	year      = {2017},
	url       = {https://openreview.net/forum?id=Hk95PK9le},
	timestamp = {Thu, 25 Jul 2019 14:25:56 +0200},
	biburl    = {https://dblp.org/rec/conf/iclr/DozatM17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{2020-yu-al,
	title = "Neural Mention Detection",
	author = "Yu, Juntao  and
	Bohnet, Bernd  and
	Poesio, Massimo",
	booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
	month = may,
	year = "2020",
	address = "Marseille, France",
	publisher = "European Language Resources Association",
	url = "https://aclanthology.org/2020.lrec-1.1",
	pages = "1--10",
	abstract = "Mention detection is an important preprocessing step for annotation and interpretation in applications such as NER and coreference resolution, but few stand-alone neural models have been proposed able to handle the full range of mentions. In this work, we propose and compare three neural network-based approaches to mention detection. The first approach is based on the mention detection part of a state of the art coreference resolution system; the second uses ELMO embeddings together with a bidirectional LSTM and a biaffine classifier; the third approach uses the recently introduced BERT model. Our best model (using a biaffine classifier) achieves gains of up to 1.8 percentage points on mention recall when compared with a strong baseline in a HIGH RECALL coreference annotation setting. The same model achieves improvements of up to 5.3 and 6.2 p.p. when compared with the best-reported mention detection F1 on the CONLL and CRAC coreference data sets respectively in a HIGH F1 annotation setting. We then evaluate our models for coreference resolution by using mentions predicted by our best model in start-of-the-art coreference systems. The enhanced model achieved absolute improvements of up to 1.7 and 0.7 p.p. when compared with our strong baseline systems (pipeline system and end-to-end system) respectively. For nested NER, the evaluation of our model on the GENIA corpora shows that our model matches or outperforms state-of-the-art models despite not being specifically designed for this task.",
	language = "English",
	ISBN = "979-10-95546-34-4",
}


@inproceedings{2013-uryupina-moschitti,
	title = "Multilingual Mention Detection for Coreference Resolution",
	author = "Uryupina, Olga  and
	Moschitti, Alessandro",
	booktitle = "Proceedings of the Sixth International Joint Conference on Natural Language Processing",
	month = oct,
	year = "2013",
	address = "Nagoya, Japan",
	publisher = "Asian Federation of Natural Language Processing",
	url = "https://aclanthology.org/I13-1012",
	pages = "100--108",
}

@article{2013-lee-al,
	title = "Deterministic Coreference Resolution Based on Entity-Centric, Precision-Ranked Rules",
	author = "Lee, Heeyoung  and
	Chang, Angel  and
	Peirsman, Yves  and
	Chambers, Nathanael  and
	Surdeanu, Mihai  and
	Jurafsky, Dan",
	journal = "Computational Linguistics",
	volume = "39",
	number = "4",
	year = "2013",
	url = "https://aclanthology.org/J13-4004",
	doi = "10.1162/COLI_a_00152",
	pages = "885--916",
}

@book{2014-halliday-hasan,
	title={Cohesion in English},
	author={Halliday, M.A.K. and Hasan, R.},
	isbn={9781317869603},
	series={English Language Series},
	url={https://books.google.dz/books?id=rAOtAgAAQBAJ},
	year={2014},
	publisher={Taylor \& Francis}
}

@book{2015-schmolz,
	author = {Helene Schmolz},
	doi = {doi:10.1515/9783110416756},
	url = {https://doi.org/10.1515/9783110416756},
	title = {Anaphora Resolution and Text Retrieval},
	year = {2015},
	publisher = {De Gruyter},
	ISBN = {978-3-11-041675-6}
}

@incollection{10-palmer,
	author = {David D. Palmer},
	title = {Text Preprocessing},
	booktitle = {Handbook of Natural Language Processing},
	edition = {deuxi\`eme}, 
	editor = {Nitin Indurkhya and Fred J. Damerau},
	publisher = {CRC Press,Taylor and Francis Group},
	address = {Boca Raton, FL},
	year = {2010},
	series = {Machine learning \& Pattern Recognition},
	isbn = {978-1-4200-8593-8},
}

@inproceedings{97-reynar-ratnaparkhi,
	author = {Reynar, Jeffrey C. and Ratnaparkhi, Adwait},
	title = {A maximum entropy approach to identifying sentence boundaries},
	booktitle = {Proceedings of the fifth conference on Applied natural language processing},
	series = {ANLC '97},
	year = {1997},
	location = {Washington, DC},
	pages = {16--19},
	numpages = {4},
	url = {http://dx.doi.org/10.3115/974557.974561},
	doi = {10.3115/974557.974561},
	acmid = {974561},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
}

@inproceedings{89-riley,
	author = {Riley, Michael D.},
	title = {Some applications of tree-based modelling to speech and language},
	booktitle = {Proceedings of the workshop on Speech and Natural Language},
	series = {HLT '89},
	year = {1989},
	isbn = {1-55860-112-0},
	location = {Cape Cod, Massachusetts},
	pages = {339--352},
	numpages = {14},
	url = {http://dx.doi.org/10.3115/1075434.1075492},
	doi = {10.3115/1075434.1075492},
	acmid = {1075492},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
}

@article{97-palmer-hearst,
	author = {Palmer, David D. and Hearst, Marti A.},
	title = {Adaptive multilingual sentence boundary disambiguation},
	journal = {Comput. Linguist.},
	issue_date = {June 1997},
	volume = {23},
	number = {2},
	month = jun,
	year = {1997},
	issn = {0891-2017},
	pages = {241--267},
	numpages = {27},
	url = {http://dl.acm.org/citation.cfm?id=972695.972697},
	acmid = {972697},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
}

@inproceedings{97-palmer,
	author = {Palmer, David D.},
	title = {A trainable rule-based algorithm for word segmentation},
	booktitle = {Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics},
	series = {ACL '98},
	year = {1997},
	location = {Madrid, Spain},
	pages = {321--328},
	numpages = {8},
	url = {http://dx.doi.org/10.3115/976909.979658},
	doi = {10.3115/976909.979658},
	acmid = {979658},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
}

@Misc{2018-texas,
	author = {Raymond J. Mooney},
	title = {Introduction},
	howpublished = {Cours "CS 388: Natural Language Processing"},
	year = {2018},
	note = {University of Texas at Austin},
	OPTannote = {annote},
}

@ARTICLE{1951-shannon,
	author={C. E. {Shannon}},
	journal={The Bell System Technical Journal}, 
	title={Prediction and entropy of printed English}, 
	year={1951},
	volume={30},
	number={1},
	pages={50-64},
}

@article{1961-joshi,
	title={Computation of syntactic structure},
	author={Joshi, Aravind K},
	journal={Advances in Documentation and Library Science},
	volume={3},
	number={part 2},
	pages={831--840},
	year={1961}
}

@book{1962-harris,
	title={String analysis of sentence structure},
	author={Harris, Zellig Sabbettai},
	number={1},
	year={1962},
	publisher={Mouton}
}

@Misc{1964-bobrow,
	title={Natural Language Input for a Computer Problem Solving System},
	author={Bobrow, Daniel G},
	year={1964},
	publisher={Massachusetts Institute of Technology},
	type = {PhD},
	institution = {Massachusetts Institute of Technology},
}


@article{1958-luhn,
	title={The automatic creation of literature abstracts},
	author={Luhn, Hans Peter},
	journal={IBM Journal of research and development},
	volume={2},
	number={2},
	pages={159--165},
	year={1958},
	publisher={Ibm}
}

@inproceedings {99-sparckjones,
	author = {Sparck Jones, Karen},
	title = {Automatic summarising: factors and directions},
	booktitle = {Advances in automatic text summarisation},
	publisher = {Cambridge MA: MIT Press},
	year = {1999},
}

@inproceedings{98-hovy-lin,
	author = {Hovy, Eduard and Lin, Chin-Yew},
	booktitle = {Proceedings of a workshop on held at Baltimore, Maryland: October 13-15, 1998},
	keywords = {summarization},
	organization = {Association for Computational Linguistics},
	pages = {197--214},
	title = {Automated text summarization and the {SUMMARIST} system},
	year = {1998}
}

@Inbook{1994-Jones,
	author="Jones, Karen Sparck",
	editor="Zampolli, Antonio
	and Calzolari, Nicoletta
	and Palmer, Martha",
	title="Natural Language Processing: A Historical Review",
	bookTitle="Current Issues in Computational Linguistics: In Honour of Don Walker",
	year="1994",
	publisher="Springer Netherlands",
	address="Dordrecht",
	pages="3--16",
	abstract="This paper reviews natural language processing (NLP) from the late 1940's to the present, seeking to identify its successive trends as these reflect concerns with different problems or the pursuit of different approaches to solving these problems and building systems as wholes. The review distinguishes four phases in the history of NLP, characterised respectively by an emphasis on machine translation, by the influence of artificial intelligence, by the adoption of a logico-grammatical style, and by an attack on massive language data. The account considers the significant and salient work in each phase, and concludes with an assessment of where we stand after more than forty years of effort in the field.",
	isbn="978-0-585-35958-8",
	doi="10.1007/978-0-585-35958-8_1",
	url="https://doi.org/10.1007/978-0-585-35958-8_1"
}

@Misc{1971-winograd,
	author = {Winograd, Terry},
	title = {Procedures as a Representation for Data in a Computer Program for Understanding Natural Language},
	type = {Technical report},
	institution = {MIT},
	year = {1971},
}

@incollection{1975-schank,
	title = "CHAPTER 1 - MARGIE",
	editor = "ROGER C. SCHANK",
	booktitle = "Conceptual Information Processing",
	publisher = "North-Holland",
	pages = "1 - 4",
	year = "1975",
	isbn = "978-1-4832-2973-7",
	doi = "https://doi.org/10.1016/B978-1-4832-2973-7.50005-5",
	url = "http://www.sciencedirect.com/science/article/pii/B9781483229737500055",
	author = "ROGER C. SCHANK"
}

@ARTICLE{1975-baker,
	author={J. {Baker}},
	journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
	title={The DRAGON system--An overview}, 
	year={1975},
	volume={23},
	number={1},
	pages={24-29},
}

@article{1987-sag-pollard,
	title={Information-based syntax and semantics},
	author={Sag, Ivan A and Pollard, Carl},
	journal={CSLI lecture notes},
	volume={13},
	year={1987}
}

@inproceedings{1988-church,
	author = {Church, Kenneth Ward},
	title = {A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text},
	year = {1988},
	publisher = {Association for Computational Linguistics},
	address = {USA},
	url = {https://doi.org/10.3115/974235.974260},
	doi = {10.3115/974235.974260},
	booktitle = {Proceedings of the Second Conference on Applied Natural Language Processing},
	pages = {136–143},
	numpages = {8},
	location = {Austin, Texas},
	series = {ANLC ’88}
}

@article{1993-brown-al,
	title = "The Mathematics of Statistical Machine Translation: Parameter Estimation",
	author = "Brown, Peter F.  and
	Della Pietra, Stephen A.  and
	Della Pietra, Vincent J.  and
	Mercer, Robert L.",
	journal = "Computational Linguistics",
	volume = "19",
	number = "2",
	year = "1993",
	url = "https://aclanthology.org/J93-2003",
	pages = "263--311",
}

@article{1990-brown-al,
	title = "A Statistical Approach to Machine Translation",
	author = "Brown, Peter F.  and
	Cocke, John  and
	Della Pietra, Stephen A.  and
	Della Pietra, Vincent J.  and
	Jelinek, Fredrick  and
	Lafferty, John D.  and
	Mercer, Robert L.  and
	Roossin, Paul S.",
	journal = "Computational Linguistics",
	volume = "16",
	number = "2",
	year = "1990",
	url = "https://www.aclweb.org/anthology/J90-2002",
	pages = "79--85",
}

@InProceedings{1996-magerman,
	author="Magerman, David M.",
	editor="Miclet, Laurent
	and de la Higuera, Colin",
	title="Learning grammatical structure using statistical decision-trees",
	booktitle="Grammatical Interference: Learning Syntax from Sentences",
	year="1996",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="1--21",
	abstract="In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which avoids the difficulties of grammar development simply by having no grammar. Instead, the parser is driven by statistical pattern recognizers, in the form of decision trees, trained on correctly parsed sentences. This approach to grammatical inference results in a parser which constructs a complete parse for every sentence and achieves accuracy rates far better than any previously published result.",
	isbn="978-3-540-70678-6"
}

@inproceedings{1980-bobrow,
	title={Knowledge Representation for Syntactic/Semantic Processing.},
	author={Bobrow, Robert J and Webber, Bonnie L},
	booktitle={AAAI},
	pages={316--323},
	year={1980}
}

@inproceedings{1986-jacobs,
	author = {Jacobs, Paul S.},
	title = {Language Analysis in Not-so-Limited Domains},
	year = {1986},
	isbn = {0818647434},
	publisher = {IEEE Computer Society Press},
	address = {Washington, DC, USA},
	booktitle = {Proceedings of 1986 ACM Fall Joint Computer Conference},
	pages = {247–252},
	numpages = {6},
	location = {Dallas, Texas, USA},
	series = {ACM ’86}
}

@article{1995-miller,
	title={WordNet: a lexical database for English},
	author={Miller, George A},
	journal={Communications of the ACM},
	volume={38},
	number={11},
	pages={39--41},
	year={1995},
	publisher={ACM New York, NY, USA}
}

@article{2003-bengio-al,
	title={A neural probabilistic language model},
	author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
	journal={Journal of machine learning research},
	volume={3},
	number={Feb},
	pages={1137--1155},
	year={2003}
}

@book{2020-jurafsky-martin,
	author = {Jurafsky, Dan and Martin, James H.},
	title = {Speech and Language Processing},
	year = {2020},
	note = {\url{https://web.stanford.edu/~jurafsky/slp3/}},
}

@article{1993-marcus-al,
	title = "Building a Large Annotated Corpus of {E}nglish: The {P}enn {T}reebank",
	author = "Marcus, Mitchell P.  and
	Santorini, Beatrice  and
	Marcinkiewicz, Mary Ann",
	journal = "Computational Linguistics",
	volume = "19",
	number = "2",
	year = "1993",
	url = "https://www.aclweb.org/anthology/J93-2004",
	pages = "313--330",
}

@inproceedings{2014-lebret-collobert,
	title = "Word Embeddings through Hellinger {PCA}",
	author = "Lebret, R{\'e}mi  and
	Collobert, Ronan",
	booktitle = "Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
	month = apr,
	year = "2014",
	address = "Gothenburg, Sweden",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/E14-1051",
	doi = "10.3115/v1/E14-1051",
	pages = "482--490",
}

@article{2018-devlin-al,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{2018-peters-al,
	title={Deep contextualized word representations},
	author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	journal={arXiv preprint arXiv:1802.05365},
	year={2018}
}

@inproceedings{2018-howard-ruder,
	title = "Universal Language Model Fine-tuning for Text Classification",
	author = "Howard, Jeremy  and
	Ruder, Sebastian",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P18-1031",
	doi = "10.18653/v1/P18-1031",
	pages = "328--339",
	abstract = "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.",
}

@misc{2018-radford-al,
	title={Improving language understanding by generative pre-training},
	author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year={2018}
}

@article{2019-lample-conneau,
	title={Cross-lingual language model pretraining},
	author={Lample, Guillaume and Conneau, Alexis},
	journal={arXiv preprint arXiv:1901.07291},
	year={2019}
}

@book{2009-ball,
	author = {Rodney Ball},
	title = {Introduction to Phonetics for Students of English, French, German and Spanish},
	year = {2009},
	publisher = {HumBox Project},
}

@book{2009-lieber,
	author = {Rochelle Lieber},
	title = {Introducing Morphology},
	year = {2009},
	publisher = {Cambridge University Press},
	isbn = {978-0-511-77018-0},
}

@book{2018-anderson,
	author = {Catherine Anderson},
	title = {Essentials of Linguistics},
	year = {2018},
	publisher = {McMaster University},
}

@book{2011-aronoff-fudeman,
	author = {Mark Aronoff and Kirsten Fudeman},
	title = {Introducing Morphology},
	year = {2011},
	publisher = {Wiley-Blackwell Publishing Ltd},
	isbn = {978-1-4051-9467-9},
}


@Misc{2014-univ,
	author = {{Universal Dependencies contributors}},
	title = {Universal Dependencies},
	howpublished = {Site web},
	year = {2014},
	note = {URL : \url{https://universaldependencies.org/} [visité le 3 juillet 2020]},
}


@book{2001-akmajian,
	author = {Adrian Akmajian and Richard A. Demers and Ann K. Farmer and Robert M. Harnish},
	title = {Linguistics, An Introduction to Language and Communication},
	year = {2001},
	publisher = {The MIT Press},
	edition = {fifth},
}

@article{1988-blake, 
	title={Basic word order. Functional principles}, 
	volume={24}, 
	DOI={10.1017/S0022226700011646}, 
	number={1}, 
	journal={Journal of Linguistics}, 
	publisher={Cambridge University Press}, 
	author={Blake, Barry B.}, 
	year={1988}, 
	pages={213–217}
}

@book{2008-tellier,
	title={Introduction au TALN et à l'ingénierie linguistique},
	author={Tellier, Isabelle},
	year={2008},
	publisher={Université de Lille3}
}

@book{2019-jurafsky-martin,
	author = {Jurafsky, Dan and Martin, James H.},
	title = {Speech and Language Processing},
	year = {2019},
	url = {https://web.stanford.edu/~jurafsky/slp3/},
}

@book{2018-kroeger,
	title = {Analyzing meaning: An introduction to semantics and pragmatics},
	year = {2018},
	author = {Paul Kroeger},
	publisher = {Language Science Press}, 
	edition = {2nd},
	isbn = {978-3-96110-034-7},
	doi = {10.5281/zenodo.1164112},
	location = {Berlin},
}

@book{2007-hurford-al,
	title = {Semantics: A Coursebook},
	year = {2007},
	author = {James R. Hurford and Brendan Heasley and Michael B. Smith},
	publisher = {Cambridge University Press}, 
	edition = {2nd},
	isbn = {978-0-511-28489-2},
}

@book{2002-russell-norvig,
	title = {Artificial Intelligence: A Modern Approach},
	year = {2002},
	author = {Stuart Russell and Peter Norvig},
	publisher = {Prentice Hall}, 
	edition = {2nd},
}

@book{2006-griffiths,
	title = {An introduction to English semantics and pragmatics},
	year = {2006},
	author = {Patrick Griffiths},
	publisher = {Edinburgh university press}, 
}

@article{1979-Grice,
	title={Logique et conversation},
	author={H. Paul Grice},
	journal={Communications},
	year={1979},
	volume={30},
	pages={57-72}
}

@book{1962-austin,
	title = {How to do things with words},
	year = {1962},
	author = {John Langshaw Austin},
	publisher = {Oxford university press}, 
}

@inproceedings{leidner-plachouras-2017-ethical,
	title = "Ethical by Design: Ethics Best Practices for Natural Language Processing",
	author = "Leidner, Jochen L.  and
	Plachouras, Vassilis",
	booktitle = "Proceedings of the First {ACL} Workshop on Ethics in Natural Language Processing",
	month = apr,
	year = "2017",
	address = "Valencia, Spain",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W17-1604",
	doi = "10.18653/v1/W17-1604",
	pages = "30--40",
	abstract = "Natural language processing (NLP) systems analyze and/or generate human language, typically on users{'} behalf. One natural and necessary question that needs to be addressed in this context, both in research projects and in production settings, is the question how ethical the work is, both regarding the process and its outcome. Towards this end, we articulate a set of issues, propose a set of best practices, notably a process featuring an ethics review board, and sketch and how they could be meaningfully applied. Our main argument is that ethical outcomes ought to be achieved by design, i.e. by following a process aligned by ethical values. We also offer some response options for those facing ethics issues. While a number of previous works exist that discuss ethical issues, in particular around big data and machine learning, to the authors{'} knowledge this is the first account of NLP and ethics from the perspective of a principled process.",
}

@inbook{2020-bahja,
	author = {Mohammed Bahja},
	title = {Natural Language Processing Applications in Business},
	booktitle = {E-Business},
	year = {2020},
	publiser = {intechopen},
	doi = {10.5772/intechopen.92203}
}

@misc{sadasivam2020memebot,
	title={memeBot: Towards Automatic Image Meme Generation},
	author={Aadhavan Sadasivam and Kausic Gunasekar and Hasan Davulcu and Yezhou Yang},
	year={2020},
	eprint={2004.14571},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}


@book{2010-indurkhya-damerau,
	author = {Indurkhya, Nitin and Damerau, Fred J.},
	title = {Handbook of Natural Language Processing},
	year = {2010},
	isbn = {1420085921},
	publisher = {Chapman \& Hall/CRC},
	edition = {2nd}
}

@article{1980-porter,
	title={An algorithm for suffix stripping.},
	author={Porter, Martin F and others},
	journal={Program},
	volume={14},
	number={3},
	pages={130--137},
	year={1980},
	publisher={Citeseer}
}

@Misc{2020-jurafsky,
	author = {Jurafsky, Dan},
	title = {Language Modeling},
	howpublished = {Cours "CS 124: From Languages to Information"},
	year = {2020},
	note = {Stanford University},
	OPTannote = {annote},
}

@Misc{2020-smith,
	author = {Noah Smith},
	title = {Neural Models},
	howpublished = {Cours "Natural Language Processing (CSE 517)"},
	year = {2020},
	note = {University of Washington},
	OPTannote = {annote},
}

@article {2003-bengio-al,
	author = {Yoshua Bengio and Réjean Ducharme annd Pascal Vincent and Christian Jauvin},
	title = {A neural probabilistic language model},
	journal = {Journal of Machine Learning Research},
	year = {2003},
	note = {URL: \url{http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf}},
}

@inproceedings{2010-mokolov-al,
	author = {Tomas Mikolov and Martin Karafi\'{a}t and Lukas Burget and Jan Cernock\`{y} and Sanjeev
	Khudanpur},
	title = {Recurrent neural network based language model},
	booktitle = {In Proc. of Interspeech},
	year = {2010},
	note = {URL: \url{http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf}},
}


@book{2018-eisenstein,
	author = {Jacob Eisenstein},
	title = {Natural Language Processing},
	year = {2018},
}

@Inbook{2003-taylor,
	author="Taylor, Ann
	and Marcus, Mitchell
	and Santorini, Beatrice",
	editor="Abeill{\'e}, Anne",
	title="The Penn Treebank: An Overview",
	bookTitle="Treebanks: Building and Using Parsed Corpora",
	year="2003",
	publisher="Springer Netherlands",
	address="Dordrecht",
	pages="5--22",
	abstract="The Penn Treebank, in its eight years of operation (1989--1996), produced approximately 7 million words of part-of-speech tagged text, 3 million words of skeletally parsed text, over 2 million words of text parsed for predicateargument structure, and 1.6 million words of transcribed spoken text annotated for speech disfluencies. This paper describes the design of the three annotation schemes used by the Treebank: POS tagging, syntactic bracketing, and disfluency annotation and the methodology employed in production. All available Penn Treebank materials are distributed by the Linguistic Data Consortium http://www.ldc.upenn.edu.",
	isbn="978-94-010-0201-1",
	doi="10.1007/978-94-010-0201-1_1",
	url="https://doi.org/10.1007/978-94-010-0201-1_1"
}

@inproceedings{2012-petrov-al,
	title = "A Universal Part-of-Speech Tagset",
	author = "Petrov, Slav  and
	Das, Dipanjan  and
	McDonald, Ryan",
	booktitle = "Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)",
	month = may,
	year = "2012",
	address = "Istanbul, Turkey",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf",
	pages = "2089--2096",
	abstract = "To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-of-speech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts-of-speech for 22 different languages. We highlight the use of this resource via three experiments, that (1) compare tagging accuracies across languages, (2) present an unsupervised grammar induction approach that does not use gold standard part-of-speech tags, and (3) use the universal tags to transfer dependency parsers between languages, achieving state-of-the-art results.",
}

@inproceedings{2014-de-marneffe-al,
	title = "Universal {S}tanford dependencies: A cross-linguistic typology",
	author = "de Marneffe, Marie-Catherine  and
	Dozat, Timothy  and
	Silveira, Natalia  and
	Haverinen, Katri  and
	Ginter, Filip  and
	Nivre, Joakim  and
	Manning, Christopher D.",
	booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
	month = may,
	year = "2014",
	address = "Reykjavik, Iceland",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/1062_Paper.pdf",
	pages = "4585--4592",
	abstract = "Revisiting the now de facto standard Stanford dependency representation, we propose an improved taxonomy to capture grammatical relations across languages, including morphologically rich ones. We suggest a two-layered taxonomy: a set of broadly attested universal grammatical relations, to which language-specific relations can be added. We emphasize the lexicalist stance of the Stanford Dependencies, which leads to a particular, partially new treatment of compounding, prepositions, and morphology. We show how existing dependency schemes for several languages map onto the universal taxonomy proposed here and close with consideration of practical implications of dependency representation choices for NLP applications, in particular parsing.",
}

@ARTICLE{1990-deerwester-al,
	author = {Scott Deerwester and Susan T. Dumais and George W. Furnas and Thomas K. Landauer and Richard Harshman},
	title = {Indexing by latent semantic analysis},
	journal = {JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE},
	year = {1990},
	volume = {41},
	number = {6},
	pages = {391--407}
}

@misc{2013-mikolov-al,
	title={Efficient Estimation of Word Representations in Vector Space},
	author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
	year={2013},
	note={URL: \url{https://arxiv.org/abs/1301.3781}},
	eprint={1301.3781},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@inproceedings{2014-pennington-al,
	title = "{G}lo{V}e: Global Vectors for Word Representation",
	author = "Pennington, Jeffrey  and
	Socher, Richard  and
	Manning, Christopher",
	booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
	month = oct,
	year = "2014",
	address = "Doha, Qatar",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D14-1162",
	doi = "10.3115/v1/D14-1162",
	pages = "1532--1543",
}

@inproceedings{2018-peters-al,
	title = "Deep Contextualized Word Representations",
	author = "Peters, Matthew  and
	Neumann, Mark  and
	Iyyer, Mohit  and
	Gardner, Matt  and
	Clark, Christopher  and
	Lee, Kenton  and
	Zettlemoyer, Luke",
	booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
	month = jun,
	year = "2018",
	address = "New Orleans, Louisiana",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N18-1202",
	doi = "10.18653/v1/N18-1202",
	pages = "2227--2237",
	abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@misc{2015-kim-al,
	title={Character-Aware Neural Language Models},
	author={Yoon Kim and Yacine Jernite and David Sontag and Alexander M. Rush},
	year={2015},
	eprint={1508.06615},
	note = {URL :  \url{https://arxiv.org/abs/1508.06615}},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{2002-finkelstein-al,
	title = {Placing Search in Context: The Concept Revisited},
	year = {2002},
	author={Lev Finkelstein and Evgeniy Gabrilovich and Yossi Matias and Ehud Rivlin and Zach Solan and Gadi Wolfman and Eytan Ruppin},
	issue_date = {January 2002},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {20},
	number = {1},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/503104.503110},
	doi = {10.1145/503104.503110},
	journal = {ACM Trans. Inf. Syst.},
	month = jan,
	pages = {116–131},
	numpages = {16},
	keywords = {invisible web, statistical natural language processing, Search, context, semantic processing}
}

@article{2015-hill-al,
	title = "{S}im{L}ex-999: Evaluating Semantic Models With (Genuine) Similarity Estimation",
	author = "Hill, Felix  and
	Reichart, Roi  and
	Korhonen, Anna",
	journal = "Computational Linguistics",
	volume = "41",
	number = "4",
	month = dec,
	year = "2015",
	url = "https://www.aclweb.org/anthology/J15-4004",
	doi = "10.1162/COLI_a_00237",
	pages = "665--695",
}

@inproceedings{2013-mikolov-al2,
	title = "Linguistic Regularities in Continuous Space Word Representations",
	author = "Mikolov, Tomas  and
	Yih, Wen-tau  and
	Zweig, Geoffrey",
	booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
	month = jun,
	year = "2013",
	address = "Atlanta, Georgia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N13-1090",
	pages = "746--751",
}

@article {2017-caliskan-al,
	author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
	title = {Semantics derived automatically from language corpora contain human-like biases},
	volume = {356},
	number = {6334},
	pages = {183--186},
	year = {2017},
	doi = {10.1126/science.aal4230},
	publisher = {American Association for the Advancement of Science},
	abstract = {AlphaGo has demonstrated that a machine can learn how to do things that people spend many years of concentrated study learning, and it can rapidly learn how to do them better than any human can. Caliskan et al. now show that machines can learn word associations from written texts and that these associations mirror those learned by humans, as measured by the Implicit Association Test (IAT) (see the Perspective by Greenwald). Why does this matter? Because the IAT has predictive value in uncovering the association between concepts, such as pleasantness and flowers or unpleasantness and insects. It can also tease out attitudes and beliefs{\textemdash}for example, associations between female names and family or male names and career. Such biases may not be expressed explicitly, yet they can prove influential in behavior.Science, this issue p. 183; see also p. 133Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/356/6334/183},
	eprint = {https://science.sciencemag.org/content/356/6334/183.full.pdf},
	journal = {Science}
}

@article{2019-turc-al,
	title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
	author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1908.08962v2 },
	year={2019},
	note={URL: \url{https://arxiv.org/abs/1908.08962}}
}

@inproceedings{2019-devlin-al,
	title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
	author = "Devlin, Jacob  and
	Chang, Ming-Wei  and
	Lee, Kenton  and
	Toutanova, Kristina",
	booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N19-1423",
	doi = "10.18653/v1/N19-1423",
	pages = "4171--4186",
	abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@article{2016-wu-al,
	author    = {Yonghui Wu and
	Mike Schuster and
	Zhifeng Chen and
	Quoc V. Le and
	Mohammad Norouzi and
	Wolfgang Macherey and
	Maxim Krikun and
	Yuan Cao and
	Qin Gao and
	Klaus Macherey and
	Jeff Klingner and
	Apurva Shah and
	Melvin Johnson and
	Xiaobing Liu and
	Lukasz Kaiser and
	Stephan Gouws and
	Yoshikiyo Kato and
	Taku Kudo and
	Hideto Kazawa and
	Keith Stevens and
	George Kurian and
	Nishant Patil and
	Wei Wang and
	Cliff Young and
	Jason Smith and
	Jason Riesa and
	Alex Rudnick and
	Oriol Vinyals and
	Greg Corrado and
	Macduff Hughes and
	Jeffrey Dean},
	title     = {Google's Neural Machine Translation System: Bridging the Gap between
	Human and Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1609.08144},
	year      = {2016},
	url       = {http://arxiv.org/abs/1609.08144},
	archivePrefix = {arXiv},
	eprint    = {1609.08144},
	timestamp = {Thu, 14 Mar 2019 09:34:18 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/WuSCLNMKCGMKSJL16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{2017-vaswani-al,
	author    = {Ashish Vaswani and
	Noam Shazeer and
	Niki Parmar and
	Jakob Uszkoreit and
	Llion Jones and
	Aidan N. Gomez and
	Lukasz Kaiser and
	Illia Polosukhin},
	title     = {Attention Is All You Need},
	journal   = {CoRR},
	volume    = {abs/1706.03762},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03762},
	archivePrefix = {arXiv},
	eprint    = {1706.03762},
	timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{1995-miller,
	author = {Miller, George A.},
	title = {WordNet: A Lexical Database for English},
	year = {1995},
	issue_date = {Nov. 1995},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {38},
	number = {11},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/219717.219748},
	doi = {10.1145/219717.219748},
	journal = {Commun. ACM},
	month = nov,
	pages = {39–41},
	numpages = {3}
}

@book {2010-ruppenhofer-al,
	author={Josef Ruppenhofer and Michael Ellsworth and Miriam R. L Petruck and Christopher R. Johnson and Collin F. Baker and Jan Scheffczyk},
	title={FrameNet II: Extended Theory and Practice},
	year={2010}, 
	publisher={berkeley university}
}

@article{2012-navigli-ponzetto,
	author = {Roberto Navigli and Simone Paolo Ponzetto},
	title =   {{B}abel{N}et: {T}he Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network},
	journal = {Artificial Intelligence},
	year =    {2012},
	volume = {193},
	pages = {217-250}
}

@article{2020-wang-al,
	author = {Yuxuan Wang and Yutai Hou and Wanxiang Che and Ting Liu},
	title =   {From static to dynamic word representations: a survey},
	journal = {International Journal of Machine Learning and Cybernetics},
	year =    {2020},
	issn = {1868-808X},
	doi = {https://doi.org/10.1007/s13042-020-01069-8},
	publisher= {Springer Berlin Heidelberg},
}

@article{2014-moro-al,
	author    = {Andrea Moro and
	Alessandro Raganato and
	Roberto Navigli},
	title     = {{Entity Linking meets Word Sense Disambiguation: a Unified
	Approach}},
	journal   = {Transactions of the Association for Computational Linguistics (TACL)},
	volume    = {2},
	year      = {2014},
	pages     = {231-244},
}

@Inbook{2019-white-al,
	author="White, Lyndon
	and Togneri, Roberto
	and Liu, Wei
	and Bennamoun, Mohammed",
	title="Word Sense Representations",
	bookTitle="Neural Representations of Natural Language",
	year="2019",
	publisher="Springer Singapore",
	address="Singapore",
	pages="73--92",
	abstract="In this chapter, techniques for representing the multiple meanings of a single word are discussed. This is a growing area, and is particularly important in languages where polysemous and homonymous words are common. This includes English, but it is even more prevalent in Mandarin for example. The techniques discussed can broadly be classified as lexical word sense representationWord sense representation, and as word sense inductionWord Sense Induction (WSI). The inductive techniques can be sub-classified as clusteringClustering -based or as prediction-based.",
	isbn="978-981-13-0062-2",
	doi="10.1007/978-981-13-0062-2_4",
	url="https://doi.org/10.1007/978-981-13-0062-2_4"
}

@thesis{2017-djemaa,
	author = {Marianne Djemaa},
	title = {Stratégie Domaine Par Domaine Pour
	La Création d'un Framenet Du Français :
	Annotations en Corpus de Cadres et Rôles Sémantiques
	},
	type = {Thèse de doctorat de Linguistique Théorique, Descriptive et Automatique},
	institution = {Université Sorbonne Paris Cité},
	year = {2017},
}

@book{2002-russell-norvig,
	author = {Stuart J. Russell and Peter Norvig},
	title = {Artificial Intelligence: A Modern Approach},
	year = {2002},
	edition={2nd},
	publisher={Prentice Hall},
}

@Misc{2020-cmu,
	author = {Alan W. Black and David R. Mortensen},
	title = {Compositional semantics, semantic parsing},
	howpublished = {Cours "Natural Language Processing F20"},
	year = {2020},
	note = {Carnegie Mellon University},
	annote = {\url{http://demo.clab.cs.cmu.edu/NLP/}},
}

@inproceedings{2013-banarescu-al,
	title = "{A}bstract {M}eaning {R}epresentation for Sembanking",
	author = "Banarescu, Laura  and
	Bonial, Claire  and
	Cai, Shu  and
	Georgescu, Madalina  and
	Griffitt, Kira  and
	Hermjakob, Ulf  and
	Knight, Kevin  and
	Koehn, Philipp  and
	Palmer, Martha  and
	Schneider, Nathan",
	booktitle = "Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse",
	month = aug,
	year = "2013",
	address = "Sofia, Bulgaria",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W13-2322",
	pages = "178--186",
}


@inproceedings{2017-he-al,
	title = "Deep Semantic Role Labeling: What Works and What{'}s Next",
	author = "He, Luheng  and
	Lee, Kenton  and
	Lewis, Mike  and
	Zettlemoyer, Luke",
	booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2017",
	address = "Vancouver, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P17-1044",
	doi = "10.18653/v1/P17-1044",
	pages = "473--483",
	abstract = "We introduce a new deep learning model for semantic role labeling (SRL) that significantly improves the state of the art, along with detailed analyses to reveal its strengths and limitations. We use a deep highway BiLSTM architecture with constrained decoding, while observing a number of recent best practices for initialization and regularization. Our 8-layer ensemble model achieves 83.2 F1 on theCoNLL 2005 test set and 83.4 F1 on CoNLL 2012, roughly a 10{\%} relative error reduction over the previous state of the art. Extensive empirical analysis of these gains show that (1) deep models excel at recovering long-distance dependencies but can still make surprisingly obvious errors, and (2) that there is still room for syntactic parsers to improve these results.",
}

@Article{info11020074,
	AUTHOR = {Ferreira Cruz, André and Rocha, Gil and Lopes Cardoso, Henrique},
	TITLE = {Coreference Resolution: Toward End-to-End and Cross-Lingual Systems},
	JOURNAL = {Information},
	VOLUME = {11},
	YEAR = {2020},
	NUMBER = {2},
	ARTICLE-NUMBER = {74},
	URL = {https://www.mdpi.com/2078-2489/11/2/74},
	ISSN = {2078-2489},
	ABSTRACT = {The task of coreference resolution has attracted considerable attention in the literature due to its importance in deep language understanding and its potential as a subtask in a variety of complex natural language processing problems. In this study, we outlined the field&rsquo;s terminology, describe existing metrics, their differences and shortcomings, as well as the available corpora and external resources. We analyzed existing state-of-the-art models and approaches, and reviewed recent advances and trends in the field, namely end-to-end systems that jointly model different subtasks of coreference resolution, and cross-lingual systems that aim to overcome the challenges of less-resourced languages. Finally, we discussed the main challenges and open issues faced by coreference resolution systems.},
	DOI = {10.3390/info11020074}
}

@inproceedings{2016-moosavi-strube,
	title = "Which Coreference Evaluation Metric Do You Trust? A Proposal for a Link-based Entity Aware Metric",
	author = "Moosavi, Nafise Sadat  and
	Strube, Michael",
	booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = aug,
	year = "2016",
	address = "Berlin, Germany",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P16-1060",
	doi = "10.18653/v1/P16-1060",
	pages = "632--642",
}

@incollection{1967-davidson,
	added-at = {2007-12-14T02:38:06.000+0100},
	author = {Davidson, Donald},
	biburl = {https://www.bibsonomy.org/bibtex/2da38166ce77b4cae007e47f2993c9ca1/diego_ma},
	booktitle = {The Logic of Decision and Action},
	editor = {Rescher, Nicholas},
	interhash = {6d48dee932e1441b38a58f96143ba0a1},
	intrahash = {da38166ce77b4cae007e47f2993c9ca1},
	keywords = {events philosophy},
	pages = {81-120},
	publisher = {Univ. of Pittsburgh Press},
	timestamp = {2007-12-14T02:38:06.000+0100},
	title = {The Logical Form of Action Sentences},
	year = 1967
}


@article{2006-Cornish,
	author = {Francis Cornish},
	title = {Relations de cohérence en discours : critères de reconnaissance, caractérisation et articulation cohésion-cohérence},
	journaltitle = {Corela [Online]},
	year = {2006},
	doi = {https://doi.org/10.4000/corela.1456},
}

@inproceedings{2008-prasad-al,
	title = "The {P}enn {D}iscourse {T}ree{B}ank 2.0.",
	author = "Prasad, Rashmi  and
	Dinesh, Nikhil  and
	Lee, Alan  and
	Miltsakaki, Eleni  and
	Robaldo, Livio  and
	Joshi, Aravind  and
	Webber, Bonnie",
	booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
	month = may,
	year = "2008",
	address = "Marrakech, Morocco",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/754_paper.pdf",
	abstract = "We present the second version of the Penn Discourse Treebank, PDTB-2.0, describing its lexically-grounded annotations of discourse relations and their two abstract object arguments over the 1 million word Wall Street Journal corpus. We describe all aspects of the annotation, including (a) the argument structure of discourse relations, (b) the sense annotation of the relations, and (c) the attribution of discourse relations and each of their arguments. We list the differences between PDTB-1.0 and PDTB-2.0. We present representative statistics for several aspects of the annotation in the corpus.",
}

@inproceedings{2004-lethanh-al,
	title = "Generating Discourse Structures for Written Text",
	author = "Le Thanh, Huong  and
	Abeysinghe, Geetha  and
	Huyck, Christian",
	booktitle = "{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics",
	month = "aug 23{--}aug 27",
	year = "2004",
	address = "Geneva, Switzerland",
	publisher = "COLING",
	url = "https://www.aclweb.org/anthology/C04-1048",
	pages = "329--335",
}

@inproceedings{2018-wang-al,
	title = "Toward Fast and Accurate Neural Discourse Segmentation",
	author = "Wang, Yizhong  and
	Li, Sujian  and
	Yang, Jingfeng",
	booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
	month = oct # "-" # nov,
	year = "2018",
	address = "Brussels, Belgium",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D18-1116",
	doi = "10.18653/v1/D18-1116",
	pages = "962--967",
	abstract = "Discourse segmentation, which segments texts into Elementary Discourse Units, is a fundamental step in discourse analysis. Previous discourse segmenters rely on complicated hand-crafted features and are not practical in actual use. In this paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF framework. To improve its accuracy, we address the problem of data insufficiency by transferring a word representation model that is trained on a large corpus. We also propose a restricted self-attention mechanism in order to capture useful information within a neighborhood. Experiments on the RST-DT corpus show that our model is significantly faster than previous methods, while achieving new state-of-the-art performance.",
}

@inproceedings{2018-yu-al,
	title = "Transition-based Neural {RST} Parsing with Implicit Syntax Features",
	author = "Yu, Nan  and
	Zhang, Meishan  and
	Fu, Guohong",
	booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
	month = aug,
	year = "2018",
	address = "Santa Fe, New Mexico, USA",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/C18-1047",
	pages = "559--570",
	abstract = "Syntax has been a useful source of information for statistical RST discourse parsing. Under the neural setting, a common approach integrates syntax by a recursive neural network (RNN), requiring discrete output trees produced by a supervised syntax parser. In this paper, we propose an implicit syntax feature extraction approach, using hidden-layer vectors extracted from a neural syntax parser. In addition, we propose a simple transition-based model as the baseline, further enhancing it with dynamic oracle. Experiments on the standard dataset show that our baseline model with dynamic oracle is highly competitive. When implicit syntax features are integrated, we are able to obtain further improvements, better than using explicit Tree-RNN.",
}

@article{2004-poesio-al,
	title = "{C}entering: A Parametric Theory and Its Instantiations",
	author = "Poesio, Massimo  and
	Stevenson, Rosemary  and
	Di Eugenio, Barbara  and
	Hitzeman, Janet",
	journal = "Computational Linguistics",
	volume = "30",
	number = "3",
	year = "2004",
	url = "https://www.aclweb.org/anthology/J04-3003",
	doi = "10.1162/0891201041850911",
	pages = "309--363",
}

@article{2008-barzilay-lapata,
	title = "Modeling Local Coherence: An Entity-Based Approach",
	author = "Barzilay, Regina  and
	Lapata, Mirella",
	journal = "Computational Linguistics",
	volume = "34",
	number = "1",
	year = "2008",
	url = "https://www.aclweb.org/anthology/J08-1001",
	doi = "10.1162/coli.2008.34.1.1",
	pages = "1--34",
}

@inproceedings{2020-liang-al,
	title = "Extending Implicit Discourse Relation Recognition to the {PDTB}-3",
	author = "Liang, Li  and
	Zhao, Zheng  and
	Webber, Bonnie",
	booktitle = "Proceedings of the First Workshop on Computational Approaches to Discourse",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.codi-1.14",
	doi = "10.18653/v1/2020.codi-1.14",
	pages = "135--147",
	abstract = "The PDTB-3 contains many more Implicit discourse relations than the previous PDTB-2. This is in part because implicit relations have now been annotated within sentences as well as between them. In addition, some now co-occur with explicit discourse relations, instead of standing on their own. Here we show that while this can complicate the problem of identifying the location of implicit discourse relations, it can in turn simplify the problem of identifying their senses. We present data to support this claim, as well as methods that can serve as a non-trivial baseline for future state-of-the-art recognizers for implicit discourse relations.",
}


@Inbook{12-nenkova-mckeown,
	author="Nenkova, Ani
	and McKeown, Kathleen",
	OPTeditor="Aggarwal, Charu C. and Zhai, ChengXiang",
	title="A Survey of Text Summarization Techniques",
	bookTitle="Mining Text Data",
	year="2012",
	publisher="Springer US",
	address="Boston, MA",
	pages="43--76",
	abstract="Numerous approaches for identifying important content for automatic text summarization have been developed to date. Topic representation approaches first derive an intermediate representation of the text that captures the topics discussed in the input. Based on these representations of topics, sentences in the input document are scored for importance. In contrast, in indicator representation approaches, the text is represented by a diverse set of possible indicators of importance which do not aim at discovering topicality. These indicators are combined, very often using machine learning techniques, to score the importance of each sentence. Finally, a summary is produced by selecting sentences in a greedy approach, choosing the sentences that will go in the summary one by one, or globally optimizing the selection, choosing the best set of sentences to form a summary. In this chapter we give a broad overview of existing approaches based on these distinctions, with particular attention on how representation, sentence scoring or summary selection strategies alter the overall performance of the summarizer. We also point out some of the peculiarities of the task of summarization which have posed challenges to machine learning approaches for the problem, and some of the suggested solutions.",
	isbn="978-1-4614-3223-4",
	doi="10.1007/978-1-4614-3223-4_3",
	url="https://doi.org/10.1007/978-1-4614-3223-4_3"
}

@article{12-lloret-palomar,
	author = {Lloret, Elena and Palomar, Manuel},
	title = {Text Summarisation in Progress: A Literature Review},
	journal = {Artif. Intell. Rev.},
	issue_date = {January   2012},
	volume = {37},
	number = {1},
	month = jan,
	year = {2012},
	issn = {0269-2821},
	pages = {1--41},
	numpages = {41},
	url = {http://dx.doi.org/10.1007/s10462-011-9216-z},
	doi = {10.1007/s10462-011-9216-z},
	acmid = {2123810},
	publisher = {Kluwer Academic Publishers},
	address = {Norwell, MA, USA},
	keywords = {Human language technologies, Intelligent systems, Text summarisation},
} 

@article{19-aries-al,
	author    = {Abdelkrime Aries and
	Djamel Eddine Zegour and
	Walid{-}Khaled Hidouci},
	title     = {Automatic text summarization: What has been done and what has to be
	done},
	journal   = {CoRR},
	volume    = {abs/1904.00688},
	year      = {2019},
	url       = {http://arxiv.org/abs/1904.00688},
	archivePrefix = {arXiv},
	eprint    = {1904.00688},
	timestamp = {Wed, 24 Apr 2019 12:21:25 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1904-00688.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings {13-aries-al,
	author = {Aries, Abdelkrime and Oufaida, Houda and Nouali, Omar},
	title = {Using clustering and a modified classification algorithm for automatic text summarization},
	booktitle = {Proc. SPIE},
	volume = {8658},
	number = {},
	pages = {865811-865811-9},
	year = {2013},
	doi = {10.1117/12.2004001},
	URL = { http://dx.doi.org/10.1117/12.2004001}
}

@article{21-aries-al,
	author    = {Abdelkrime Aries and
	Djamel Eddine Zegour and
	Walid Khaled Hidouci},
	title={Graph-based cumulative score using statistical features for multilingual automatic text summarisation},
	journal={ Int. J. Data Mining, Modelling and Management},
	volume={13},
	year={2021},
	pages = {37--64},
}

@inproceedings{04-mihalcea-tarau,
	author = {Mihalcea, Rada and Tarau, Paul},
	url = {http://www.aclweb.org/anthology/W04-3252},
	title = {TextRank: Bringing Order into Texts},
	booktitle = {Proceedings of EMNLP 2004},
	editor = {Dekang Lin and Dekai Wu},
	year = {2004},
	month = {July},
	address = {Barcelona, Spain},
	publisher = {Association for Computational Linguistics},
	pages = {404--411}
}

@inproceedings{81-paice,
	author = {Paice, C. D.},
	title = {The automatic generation of literature abstracts: an approach based on the identification of self-indicating phrases},
	booktitle = {Proceedings of the 3rd annual ACM conference on Research and development in information retrieval},
	series = {SIGIR '80},
	year = {1981},
	isbn = {0-408-10775-8},
	location = {Cambridge, England},
	pages = {172--191},
	numpages = {20},
	url = {http://dl.acm.org/citation.cfm?id=636669.636680},
	acmid = {636680},
	publisher = {Butterworth  \& Co.},
	address = {Kent, UK, UK},
}

@inproceedings{15-oufaida-al,
	author    = {Houda Oufaida and
	Philippe Blache and
	Omar Nouali},
	editor    = {Chris Biemann and
	Siegfried Handschuh and
	Andr{\'{e}} Freitas and
	Farid Meziane and
	Elisabeth M{\'{e}}tais},
	title     = {Using Distributed Word Representations and mRMR Discriminant Analysis
	for Multilingual Text Summarization},
	booktitle = {Natural Language Processing and Information Systems - 20th International
	Conference on Applications of Natural Language to Information Systems,
	{NLDB} 2015 Passau, Germany, June 17-19, 2015 Proceedings},
	series    = {Lecture Notes in Computer Science},
	volume    = {9103},
	pages     = {51--63},
	publisher = {Springer},
	year      = {2015},
	url       = {https://doi.org/10.1007/978-3-319-19581-0\_4},
	doi       = {10.1007/978-3-319-19581-0\_4},
	timestamp = {Wed, 25 Sep 2019 18:08:44 +0200},
	biburl    = {https://dblp.org/rec/conf/nldb/OufaidaBN15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{69-edmundson,
	author = {Edmundson, H. P.},
	title = {New Methods in Automatic Extracting},
	journal = {J. ACM},
	issue_date = {April 1969},
	volume = {16},
	number = {2},
	month = apr,
	year = {1969},
	issn = {0004-5411},
	pages = {264--285},
	numpages = {22},
	url = {http://doi.acm.org/10.1145/321510.321519},
	doi = {10.1145/321510.321519},
	acmid = {321519},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@thesis{2020-aries,
	author = {Aries, Abdelkrime},
	title = {Towards improving automatic text summaries},
	type = {PhD.},
	institution = {Ecole nationale Supérieure d'Informatique (ESI), Alger},
	year = {2020},
	note = {PhD. thesis},
}

@InProceedings{15-rush-al,
	author    = {Rush, Alexander M.  and  Chopra, Sumit  and  Weston, Jason},
	title     = {A Neural Attention Model for Abstractive Sentence Summarization},
	booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
	month     = {September},
	year      = {2015},
	address   = {Lisbon, Portugal},
	publisher = {Association for Computational Linguistics},
	pages     = {379--389},
	url       = {http://aclweb.org/anthology/D15-1044}
}

@inproceedings{18-narayan-al,
	title = "Ranking Sentences for Extractive Summarization with Reinforcement Learning",
	author = "Narayan, Shashi  and
	Cohen, Shay B.  and
	Lapata, Mirella",
	booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
	month = jun,
	year = "2018",
	address = "New Orleans, Louisiana",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N18-1158",
	doi = "10.18653/v1/N18-1158",
	pages = "1747--1759",
	abstract = "Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans.",
}

@InProceedings{06-daumeiii-marcu,
	author    = {Daum\'{e} III, Hal  and  Marcu, Daniel},
	title     = {Bayesian Query-Focused Summarization},
	booktitle = {Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics},
	month     = {July},
	year      = {2006},
	address   = {Sydney, Australia},
	publisher = {Association for Computational Linguistics},
	pages     = {305--312},
	url       = {http://www.aclweb.org/anthology/P06-1039},
	doi       = {10.3115/1220175.1220214}
} 

@inproceedings{17-klein-al,
	title = "{O}pen{NMT}: Open-Source Toolkit for Neural Machine Translation",
	author = "Klein, Guillaume  and
	Kim, Yoon  and
	Deng, Yuntian  and
	Senellart, Jean  and
	Rush, Alexander",
	booktitle = "Proceedings of {ACL} 2017, System Demonstrations",
	month = jul,
	year = "2017",
	address = "Vancouver, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P17-4012",
	pages = "67--72",
}

@Inbook{06-quah,
	author="Quah, C. K.",
	title="Machine Translation Systems",
	bookTitle="Translation and Technology",
	year="2006",
	publisher="Palgrave Macmillan UK",
	address="London",
	pages="57--92",
	abstract="Machine translation is an important technology socio-politically, commercially and scientifically, despite many misconceptions about its success or lack of it over the decades. The emergence of the Internet as one of the main media of modern communication has turned translation into a bridge that connects speakers of different languages. The endless traffic of communication between different language groups requires translation, but when instant translations are needed, human translators are not able to supply them fast enough. A highly skilled profession like translation using human translators is expensive and also slow, especially when a large number of languages and subject fields are involved. In order to meet the growing translation demand, machine translation systems are seen as a cost-effective alternative to human translators in a variety of situations. Ever since the first system was built, machine translation has been presenting scientific challenges (see also Nirenburg 1996). It became the testing ground for many experiments and applications for natural-language processing, artificial intelligence and even linguistics (Arnold etal. 1994: 4--5).",
	isbn="978-0-230-28710-5",
	doi="10.1057/9780230287105_4",
	url="https://doi.org/10.1057/9780230287105_4"
}

@inproceedings{96-vogel-al,
	title = "{HMM}-Based Word Alignment in Statistical Translation",
	author = "Vogel, Stephan  and
	Ney, Hermann  and
	Tillmann, Christoph",
	booktitle = "{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics",
	year = "1996",
	url = "https://www.aclweb.org/anthology/C96-2141",
}

@InProceedings{98-czuba-al,
	title={Can Practical Interlinguas Be Used for Difficult Analysis Problems?},
	author={Czuba, Krzysztof and Mitamura, Teruko and Nyberg, Eric H},
	year={1998},
	booktitle = {Proceedings of AMTA-98 Workshop on Interlinguas}
}

@InProceedings{00-nyberg-al,
	author="Nyberg, Eric
	and Mitamura, Teruko",
	editor="White, John S.",
	title="The KANTOO Machine Translation Environment",
	booktitle="Envisioning Machine Translation in the Information Future",
	year="2000",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="192--195",
	abstract="In this paper we describe the KANTOO machine translation environment, a set of software services and tools for multilingual document production. KANTOO includes modules for source language analysis, target language generation, source terminology management, target terminology management, and knowledge source development. The KANTOOsystem represents a complete re-design and re-implementation of the KANT machine translation system.",
	isbn="978-3-540-39965-0"
}

%============== chapitre 10

@article{11-forcada-al,
	author    = {Mikel L. Forcada and 
	Mireia Ginestí-Rosell and 
	Jacob Nordfalk and 
	Jim O'Regan and 
	Sergio Ortiz-Rojas and 
	Juan Antonio Pérez-Ortiz and 
	Felipe Sánchez-Martínez and 
	Gema Ramírez-Sánchez and 
	Francis M. Tyers},
	title     = {Apertium: a free/open-source platform for rule-based machine translation},
	journal   = {Machine Translation},
	volume    = {25},
	year      = {2011},
	doi = {https://doi.org/10.1007/s10590-011-9090-0},
}

@thesis{15-bigvand,
	author = {Anahita Mansouri Bigvand},
	title = {Word Alignment for Statistical Machine	Translation Using Hidden Markov Models},
	type = {Master},
	institution = {SIMON FRASER UNIVERSITY},
	year = {2015},
}


@inproceedings{07-koehn-al,
	title = "{M}oses: Open Source Toolkit for Statistical Machine Translation",
	author = "Koehn, Philipp  and
	Hoang, Hieu  and
	Birch, Alexandra  and
	Callison-Burch, Chris  and
	Federico, Marcello  and
	Bertoldi, Nicola  and
	Cowan, Brooke  and
	Shen, Wade  and
	Moran, Christine  and
	Zens, Richard  and
	Dyer, Chris  and
	Bojar, Ond{\v{r}}ej  and
	Constantin, Alexandra  and
	Herbst, Evan",
	booktitle = "Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
	month = jun,
	year = "2007",
	address = "Prague, Czech Republic",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P07-2045",
	pages = "177--180",
}

@manual{21-koehn,
	author = {Philipp Koehn},
	title = {{M}oses: Statistical Machine Translation System (User Manual and Code Guide)},
	year = {2021},
	url = {http://www.statmt.org/moses/manual/manual.pdf},
}


@inproceedings{2017-chen-al,
	title = "Reading {W}ikipedia to Answer Open-Domain Questions",
	author = "Chen, Danqi  and
	Fisch, Adam  and
	Weston, Jason  and
	Bordes, Antoine",
	booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2017",
	address = "Vancouver, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P17-1171",
	doi = "10.18653/v1/P17-1171",
	pages = "1870--1879",
	abstract = "This paper proposes to tackle open-domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.",
}

@article{2018-devlin-al,
	author    = {Jacob Devlin and
	Ming{-}Wei Chang and
	Kenton Lee and
	Kristina Toutanova},
	title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
	Understanding},
	journal   = {CoRR},
	volume    = {abs/1810.04805},
	year      = {2018},
	url       = {http://arxiv.org/abs/1810.04805},
	archivePrefix = {arXiv},
	eprint    = {1810.04805},
	timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{2020-roberts-al,
	title = "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
	author = "Roberts, Adam  and
	Raffel, Colin  and
	Shazeer, Noam",
	booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/2020.emnlp-main.437",
	doi = "10.18653/v1/2020.emnlp-main.437",
	pages = "5418--5426",
	abstract = "It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained models.",
}

@Article{2016-williams-al,
	author = {Williams, Jason and Raux, Antoine and Henderson, Matthew},
	title = {The Dialog State Tracking Challenge Series: A Review},
	year = {2016},
	month = {April},
	abstract = {In a spoken dialog system, dialog state tracking refers to the task of correctly inferring the state of the conversation – such as the user’s goal – given all of the dialog history up to that turn. Dialog state tracking is crucial to the success of a dialog system, yet until recently there were no common resources, hampering progress. The Dialog State Tracking Challenge series of 3 tasks introduced the first shared testbed and evaluation metrics for dialog state tracking, and has underpinned three key advances in dialog state tracking: the move from generative to discriminative models; the adoption of discriminative sequential techniques; and the incorporation of the speech recognition results directly into the dialog state tracker. This paper reviews this research area, covering both the challenge tasks themselves and summarizing the work they have enabled.},
	url = {https://www.microsoft.com/en-us/research/publication/the-dialog-state-tracking-challenge-series-a-review/},
	journal = {Dialogue \& Discourse},
}

@article{2010-young-al,
	author = {Young, Steve and Ga\v{s}i\'{c}, Milica and Keizer, Simon and Mairesse, Fran\c{c}ois and Schatzmann, Jost and Thomson, Blaise and Yu, Kai},
	title = {The Hidden Information State Model: A Practical Framework for POMDP-Based Spoken Dialogue Management},
	year = {2010},
	issue_date = {April, 2010},
	publisher = {Academic Press Ltd.},
	address = {GBR},
	volume = {24},
	number = {2},
	issn = {0885-2308},
	url = {https://doi.org/10.1016/j.csl.2009.04.001},
	doi = {10.1016/j.csl.2009.04.001},
	abstract = {This paper explains how Partially Observable Markov Decision Processes (POMDPs) can provide a principled mathematical framework for modelling the inherent uncertainty in spoken dialogue systems. It briefly summarises the basic mathematics and explains why exact optimisation is intractable. It then describes in some detail a form of approximation called the Hidden Information State model which does scale and which can be used to build practical systems. A prototype HIS system for the tourist information domain is evaluated and compared with a baseline MDP system using both user simulations and a live user trial. The results give strong support to the central contention that the POMDP-based framework is both a tractable and powerful approach to building more robust spoken dialogue systems.},
	journal = {Comput. Speech Lang.},
	month = apr,
	pages = {150–174},
	numpages = {25},
	keywords = {POMDP, Statistical dialogue systems, Hidden Information State model}
}

@article{1966-Weizenbaum,
	author = {Weizenbaum, Joseph},
	title = {ELIZA—a Computer Program for the Study of Natural Language Communication between Man and Machine},
	year = {1966},
	issue_date = {Jan. 1966},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {9},
	number = {1},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/365153.365168},
	doi = {10.1145/365153.365168},
	journal = {Commun. ACM},
	month = jan,
	pages = {36–45},
	numpages = {10}
}

@article{14-medhat-al,
	title = {Sentiment analysis algorithms and applications: A survey},
	journal = {Ain Shams Engineering Journal},
	volume = {5},
	number = {4},
	pages = {1093-1113},
	year = {2014},
	issn = {2090-4479},
	doi = {https://doi.org/10.1016/j.asej.2014.04.011},
	url = {https://www.sciencedirect.com/science/article/pii/S2090447914000550},
	author = {Walaa Medhat and Ahmed Hassan and Hoda Korashy},
	keywords = {Sentiment analysis, Sentiment classification, Feature selection, Emotion detection, Transfer learning, Building resources},
	abstract = {Sentiment Analysis (SA) is an ongoing field of research in text mining field. SA is the computational treatment of opinions, sentiments and subjectivity of text. This survey paper tackles a comprehensive overview of the last update in this field. Many recently proposed algorithms' enhancements and various SA applications are investigated and presented briefly in this survey. These articles are categorized according to their contributions in the various SA techniques. The related fields to SA (transfer learning, emotion detection, and building resources) that attracted researchers recently are discussed. The main target of this survey is to give nearly full image of SA techniques and the related fields with brief details. The main contributions of this paper include the sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas.}
}

@inproceedings{2016-elhaj-rayson,
	title = "{OSMAN} ― A Novel {A}rabic Readability Metric",
	author = "El-Haj, Mahmoud  and
	Rayson, Paul",
	booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
	month = may,
	year = "2016",
	address = "Portoro{\v{z}}, Slovenia",
	publisher = "European Language Resources Association (ELRA)",
	url = "https://aclanthology.org/L16-1038",
	pages = "250--255",
	abstract = "We present OSMAN (Open Source Metric for Measuring Arabic Narratives) - a novel open source Arabic readability metric and tool. It allows researchers to calculate readability for Arabic text with and without diacritics. OSMAN is a modified version of the conventional readability formulas such as Flesch and Fog. In our work we introduce a novel approach towards counting short, long and stress syllables in Arabic which is essential for judging readability of Arabic narratives. We also introduce an additional factor called {``}Faseeh{''} which considers aspects of script usually dropped in informal Arabic writing. To evaluate our methods we used Spearman{'}s correlation metric to compare text readability for 73,000 parallel sentences from English and Arabic UN documents. The Arabic sentences were written with the absence of diacritics and in order to count the number of syllables we added the diacritics in using an open source tool called Mishkal. The results show that OSMAN readability formula correlates well with the English ones making it a useful tool for researchers and educators working with Arabic text.",
}

@article{19-yue-al,
	title = {A survey of sentiment analysis in social media},
	journal = {Knowledge and Information Systems},
	volume = {60},
	number = {2},
	pages = {617--663},
	year = {2019},
	issn = {0219-3116},
	doi = {10.1007/s10115-018-1236-4},
	url = {https://doi.org/10.1007/s10115-018-1236-4},
	author = {Yue, Lin and Chen, Weitong and Li, Xue and Zuo, Wanli and Yin, Minghao},
	abstract = {Sentiments or opinions from social media provide the most up-to-date and inclusive information, due to the proliferation of social media and the low barrier for posting the message. Despite the growing importance of sentiment analysis, this area lacks a concise and systematic arrangement of prior efforts. It is essential to: (1) analyze its progress over the years, (2) provide an overview of the main advances achieved so far, and (3) outline remaining limitations. Several essential aspects, therefore, are addressed within the scope of this survey. On the one hand, this paper focuses on presenting typical methods from three different perspectives (task-oriented, granularity-oriented, methodology-oriented) in the area of sentiment analysis. Specifically, a large quantity of techniques and methods are categorized and compared. On the other hand, different types of data and advanced tools for research are introduced, as well as their limitations. On the basis of these materials, the essential prospects lying ahead for sentiment analysis are identified and discussed.}
}

@InProceedings{18-bettiche-al,
	author="Bettiche, Mehdi
	and Mouffok, Moncef Zakaria
	and Zakaria, Chahnez",
	editor="Medina, Jes{\'u}s
	and Ojeda-Aciego, Manuel
	and Verdegay, Jos{\'e} Luis
	and Perfilieva, Irina
	and Bouchon-Meunier, Bernadette
	and Yager, Ronald R.",
	title="Opinion Mining in Social Networks for Algerian Dialect",
	booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems. Applications",
	year="2018",
	publisher="Springer International Publishing",
	address="Cham",
	pages="629--641",
	abstract="There has been a significant increase in the volume of Arabic dialect messages on social networks, providing a rich source for opinion mining research. Most research works done on Arabic dialect focus on messages written in Arabic script, with very limited scope on Latin script. In this paper, we are interested in the classification of social networks messages retrieved from Twitter, Facebook and YouTube written in Algerian dialect in Latin script into positive or negative classes using existing opinion mining approaches (lexical-based, machine learning, and hybrid). Also, we apply a regrouping process in the preprocessing step to overcome the issues related to the Algerian dialect such as the orthographic varieties to express the same word. Furthermore, we focus on the hybrid approach which consists in automatically annotating the training corpus with the lexical-based approach and then use the machine learning approach on this corpus for creating the classification model. This approach allows classifying the messages into positive or negative classes, without having to annotate manually a training corpus.",
	isbn="978-3-319-91479-4"
}

@inproceedings{18-guellil-al,
	title = "{A}rabizi sentiment analysis based on transliteration and automatic corpus annotation",
	author = "Guellil, Imane  and
	Adeel, Ahsan  and
	Azouaou, Faical  and
	Benali, Fodil  and
	Hachani, Ala-eddine  and
	Hussain, Amir",
	booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
	month = oct,
	year = "2018",
	address = "Brussels, Belgium",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W18-6249",
	doi = "10.18653/v1/W18-6249",
	pages = "335--341",
	abstract = "Arabizi is a form of writing Arabic text which relies on Latin letters, numerals and punctuation rather than Arabic letters. In the literature, the difficulties associated with Arabizi sentiment analysis have been underestimated, principally due to the complexity of Arabizi. In this paper, we present an approach to automatically classify sentiments of Arabizi messages into positives or negatives. In the proposed approach, Arabizi messages are first transliterated into Arabic. Afterwards, we automatically classify the sentiment of the transliterated corpus using an automatically annotated corpus. For corpus validation, shallow machine learning algorithms such as Support Vectors Machine (SVM) and Naive Bays (NB) are used. Simulations results demonstrate the outperformance of NB algorithm over all others. The highest achieved F1-score is up to 78{\%} and 76{\%} for manually and automatically transliterated dataset respectively. Ongoing work is aimed at improving the transliterator module and annotated sentiment dataset.",
}

@article{20-Pantula-Kuppusamy,
	author = {Pantula, Muralidhar and Kuppusamy, K S},
	title = "{A Machine Learning-Based Model to Evaluate Readability and Assess Grade Level for the Web Pages}",
	journal = {The Computer Journal},
	year = {2020},
	month = {09},
	abstract = "{Evaluating readability of web documents has gained attention due to several factors such as improving the effectiveness of writing and to reach a wider spectrum of audience. Current practices in this direction follow several statistical measures in evaluating readability of the document. In this paper, we have proposed a machine learning-based model to compute readability of web pages. The minimum educational standards required (grade level) to understand the contents of a web page are also computed. The proposed model classifies the web pages into highly readable, readable or less readable using specified feature set. To classify a web page with the aforementioned categories, we have incorporated the features such as sentence count, word count, syllable count, type-token ratio and lexical ambiguity. To increase the usability of the proposed model, we have developed an accessible browser extension to perform the assessments of every web page loaded into the browser.}",
	issn = {0010-4620},
	doi = {10.1093/comjnl/bxaa113},
	url = {https://doi.org/10.1093/comjnl/bxaa113},
	note = {bxaa113},
	eprint = {https://academic.oup.com/comjnl/advance-article-pdf/doi/10.1093/comjnl/bxaa113/33721558/bxaa113.pdf},
}


@book{dubay2004principles,
	title={The Principles of Readability},
	author={DuBay, W.H.},
	url={https://books.google.dz/books?id=Aj0VvwEACAAJ},
	year={2004},
	publisher={ERIC Clearinghouse}
}

@article{2014-collins,
	title={Computational assessment of text readability: A survey of current and future research},
	author={Collins-Thompson, Kevyn},
	journal={ITL-International Journal of Applied Linguistics},
	volume={165},
	number={2},
	pages={97--135},
	year={2014},
	publisher={John Benjamins}
}

@Article{2020-malik-al,
	author={Malik, Mishaim
	and Malik, Muhammad Kamran
	and Mehmood, Khawar
	and Makhdoom, Imran},
	title={Automatic speech recognition: a survey},
	journal={Multimedia Tools and Applications},
	year={2020},
	month={Nov},
	day={10},
	abstract={Recently great strides have been made in the field of automatic speech recognition (ASR) by using various deep learning techniques. In this study, we present a thorough comparison between cutting-edged techniques currently being used in this area, with a special focus on the various deep learning methods. This study explores different feature extraction methods, state-of-the-art classification models, and vis-a-vis their impact on an ASR. As deep learning techniques are very data-dependent different speech datasets that are available online are also discussed in detail. In the end, the various online toolkits, resources, and language models that can be helpful in the formulation of an ASR are also proffered. In this study, we captured every aspect that can impact the performance of an ASR. Hence, we speculate that this work is a good starting point for academics interested in ASR research.},
	issn={1573-7721},
	doi={10.1007/s11042-020-10073-7},
	url={https://doi.org/10.1007/s11042-020-10073-7}
}

@article{18-haridas,
	author = {Haridas, Arul and Marimuthu, Ramalatha and Sivakumar, Vaazi},
	year = {2018},
	month = {03},
	pages = {39-57},
	title = {A critical review and analysis on techniques of speech recognition: The road ahead},
	volume = {22},
	journal = {International Journal of Knowledge-based and Intelligent Engineering Systems},
	doi = {10.3233/KES-180374}
}


@Inbook{2017-Hinterleitner,
	author="Hinterleitner, Florian",
	title="Speech Synthesis",
	bookTitle="Quality of Synthetic Speech: Perceptual Dimensions, Influencing Factors, and Instrumental Assessment",
	year="2017",
	publisher="Springer Singapore",
	address="Singapore",
	pages="5--18",
	abstract="This chapter gives an introduction to speech synthesis. A general structure of TTS systems is introduced and the four main steps for producing a synthetic speech signal are explained. The main focus is put upon different methods for the speech signal generation, namely: parametric methods, concatenative speech synthesis, model-based synthesis approaches and hybrid models. Moreover, distortions that are specific for these systems are discussed. Finally, the open-source MaryTTS system is introduced.",
	isbn="978-981-10-3734-4",
	doi="10.1007/978-981-10-3734-4_2",
	url="https://doi.org/10.1007/978-981-10-3734-4_2"
}
