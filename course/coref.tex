% !TEX TS-program = xelatex
% !TeX program = xelatex
% !TEX encoding = UTF-8
% !TEX spellcheck = fr

%=====================================================================
\ifx\wholebook\relax\else
	\documentclass{KodeBook}
	\input{calls}
	\begin{document}
		\mainmatter
	
\fi
%=====================================================================
\changegraphpath{../img/coref/}
\chapter{Détection de la coréférence}

\begin{introduction}[LES LANG\textcolor{white}{U}ES]
	\lettrine{U}{ne} coréférence est une relation entre deux termes : un substitut et son antécédent.
	Les prénoms personnels sont un exemple des références. 
	Souvent, les phrases ne sont claires que lorsque nous connaissons le sens de leurs références. 
	La tâche qui nous permet cela est la résolution de la coréférence. 
	Parmi les tâches similaires à celle-ci, nous pouvons citer : l'annotation sémantique et la reconnaissance des entités nommées. 
	Dans ce chapitre, nous allons discuter les références dans le contexte linguistique ainsi que la résolution de la coréférence.
\end{introduction} 


Prenons l'exemple ``\expword{La fille a cueilli une fleur. Elle l'a sentie. Elle a une très bonne odeur.}" représentant trois phrases consécutives.
Afin de comprendre le sens de la deuxième phrase, nous devons savoir que ``elle" veut dire ``la fille" et ``l'" veut dire ``une fleur". 
Le pronom ``elle" de la troisième phrase est plus difficile à résoudre ; il référence la fille ou la fleur ?
En introduisant le sens de la deuxième phrase ``la fille a senti une fleur", nous pouvons déduire que ``elle" est une référence à ``une fleur".
Plusieurs tâches peuvent motiver la résolution des coréférences :
\begin{itemize}
	\item Résumé automatique : dans le cas d'un résumé automatique extractif, nous essayons d'extraire les phrases les plus pertinentes. 
	Supposons que le résumé du texte précédent soit la troisième phrase.
	Comme étape de post-traitement, nous devons remplacer les références absentes afin de donner plus de sens au résumé.
	\item Questions/Réponses : dans l'exemple précédent, la réponse de la question ``\expword{Qui a une bonne odeur ?}" n'est pas ``elle" mais plutôt ``la fleur".
	\item Système de dialogue : le système doit pouvoir lier les références utilisées par l'utilisateur afin de mener une conversation. 
	\item Traduction automatique : il existe des langues qui n'utilisent pas des références dans leurs phrases ; nous devons trouver la référence en utilisant le contexte. 
	Dans ce cas, nous pouvons utiliser cette tâche afin de trouver l'entité référencée.
\end{itemize}

%===================================================================================
\section{Références}
%===================================================================================

Une référence est définie linguistiquement dans Larousse comme : ``\textit{Propriété des signes linguistiques leur permettant de renvoyer à des entités extralinguistiques (objets ou individus appartenant au monde réel ou à un monde imaginaire)}". 
Elle est connue aussi comme ``référent".
Dans cette section, nous allons discuter les formes des références, les manières de référencement et leurs propriétés.

\subsection{Formes des références}

Les références peuvent être classifiées selon les catégories syntaxiques, en plus d'autres critères \cite{2015-schmolz}.
La forme la plus connue des références est l'utilisation des pronoms et surtout les pronoms personnels.
Un \optword{pronom} est un mot-outil utilisé afin de se substituer à un nom ou un syntagme nominal. 
La catégorie la plus connue est le pronom personnel qui sert à représenter les trois types des personnes grammaticales : l'énonciateur, le destinataire et la personne absente. 
Un exemple de ce genre de références est :  ``\expword{\underline{Karim} est entré. \underline{Il} a commencé le cours.}".
Un pronom possessif est un pronom qui renvoie à un objet possesseur (et des fois à un objet possédé).
Exemple, ``\expword{\underline{Karim} a commencé \underline{son} cours.}".
Résoudre la référence ``son" revient à répondre à la question ``le cours de qui ?". 
Un pronom démonstratif est le nom de ce que nous voulons montrer.
Exemple, ``\expword{\underline{Ces livres} sont intéressants. Je vous conseille \underline{celui-ci}.}". 
Ces trois sont les catégories les plus utilisées des pronoms.

Une autre forme de référence peut être les \optword{syntagmes nominaux}.
Ils peuvent être utilisés pour référencer des entités.
Par exemple, ``\expword{J'ai un petit \underline{chat}. \underline{Cet animal} est très méchant.}".
Afin de comprendre la deuxième phrase, nous devons savoir de quel animal nous sommes en train de parler. 
Nous pouvons trouver des \keyword[S]{syntagme}s nominaux avec un article défini qui sont en réalité des références. 
Par exemple, ``\expword{J'ai un petit \underline{chat}. \underline{Le chat} est très méchant.}".
Contrairement aux pronoms qui sont toujours des références, les \keywordpl[S]{syntagme} nominaux peuvent ne pas l'être. 
Donc, en plus de chercher l'antécédent, nous devons aussi décider si c'est une référence ou non.


Les \optword{noms propres} peuvent être liés avec d'autres noms propres. 
En général, le nom propre référence un autre nom propre complet (avec plus d'information). 
Nous pouvons citer les abréviations qui peuvent être des références vers leurs versions complètes.
Un exemple, ``\expword{L'\underline{école nationale supérieure d'informatique} se situe à Alger. Comme toutes les universités algériennes, il faut avoir le BAC pour étudier à l'\underline{ESI}.}".
Aussi, nous pouvons trouver cela dans les noms propres qui sont longs ; où la répétition prend plus d'espace. 
Dans la plupart des langues, nous avons tendance à utiliser des formes plus contractes des noms propres. 
Exemple, ``\expword{\underline{La république algérienne démocratique et populaire} est un pays d'Afrique du nord. \underline{L'Algérie} a une superficie de plus de 2 millions km\textsuperscript{2}}".

Il existe des langues où les références sont complètement omises ; ces références sont connues par le nom \optword{Anaphore zéro}. 
Lorsque nous ne voulons pas répéter le même \keyword[S]{syntagme} nominal, nous pouvons l'omettre. 
Par exemple, ``\expword{\underline{Karim} a présenté et \underline{$ \phi $} a expliqué le cours.}".
Pour trouver le sujet du verbe ``expliquer", nous devons résoudre une référence qui n'existe pas ; marquée ici par ``$ \phi $".
Dans des langues, comme le japonais, il est plus naturel d'omettre les pronoms personnels dans les phrases. 
Par exemple, ``\expword{\underline{カリムさん}はESIに生きます。\underline{$ \phi $} あそこに教えます。}". 
Ceci peut être traduit, mot par mot, comme : ``\expword{\underline{M. Karim} à l'ESI va. \underline{$ \phi $} là-bas enseigne.}".
Le pronom ``il" a été omis et peut être détecté en utilisant le contexte.

Il existe des formes plus complexes qui ne référencent pas un objet mais plutôt une action.
Une de ces formes est le \keyword[S]{syntagme} verbal (Ex. ``\expword{Si Mouloud \underline{achète un nouveau vélo}, je \underline{le ferai} aussi.}").
Dans ce cas, un \keyword[S]{syntagme} verbal ne référence qu'un autre \keyword[S]{syntagme} verbal. 
Nous pouvons utiliser des adverbes comme références (Ex. ``\expword{Moammed \underline{was too busy}, and \underline{so} was I.}").


\subsection{Manière de référencement}

Le référencement peut être classifié selon la position de la référence par rapport celle du référent en anaphore et cataphore. 
En terme de nombre des antécédents, nous pouvons avoir un antécédent unique ou des antécédents partagés. 
Selon la direction de référencement, nous pouvons avoir une référence à direction unique ou deux entités en coréférence.

\begin{itemize}
	\item \optword{Anaphore} : une référence vers un mot ou un \keyword[S]{syntagme} précédent appelé ``antécédent".
	En général, ce terme est utilisé même pour les références des éléments qui viennent après. 
	Mais ici, ce concept a un terme qui le définit (point suivant).
	Une anaphore peut être un pronom (Ex. ``\expword{\underline{Le cours} est très long. \underline{Il} prendra plus de temps.}"), un syntagme nominal (Ex. ``\expword{J'ai rencontré \underline{Fatima}. \underline{Une personne} qui adore assister les autres.}"), un zéro anaphore (Ex. ``\expword{\underline{Le chat} a attrapé la souris et \underline{$ \phi $} l'a mangé.}"), etc.
	
	\item \optword{Cataphore} : une référence vers un mot ou un \keyword[S]{syntagme} suivant appelé ``postcédent".
	Elle est comme l'anaphore, mais le référent vient après la référence. 
	Exemple d'un pronom (Ex. ``\expword{\underline{Il} est très long, \underline{ce cours}!}"), syntagme nominal (Ex. ``\expword{If you want \underline{a book}, take \underline{the one on the shelf}.}"), etc. 
	Ici, la référence de type zéro anaphore ne peut pas se manifester comme une cataphore. 
	Puisque dans les langues qui utilisent ce phénomène, nous pouvons comprendre la référence à partir du contexte (ce que nous avons déjà dit).
	
	\item \optword{Antécédents partagés} : une référence vers plusieurs mots et/ou \keywordpl[S]{syntagme}.
	Que ce soit une anaphore ou une cataphore, une référence peut avoir plusieurs référents dans une seule relation.
	Exemple, ``\expword{\underline{Le cours} sera suivi par \underline{un exercice}. \underline{Ils} sont importants pour la compréhension.}".
	Ici, la relation n'est pas binaire ; le référent est une combinaison de plusieurs éléments. 
	
	\item \optword{Syntagmes nominaux en coréférence} : deux \keywordpl[S]{syntagme} nominaux où chacun est une référence vers l'autre. 
	Dans ce cas, le premier est un référent antécédent du deuxième et au même temps le deuxième est un référent postcédent du premier.  
	Exemple, ``\expword{\underline{Certains de nos collègues} nous ont vraiment soutenu. \underline{Ce genre de personnes} gagne notre gratitude.}".
	
\end{itemize}

Dans ce que nous avons présenté, le référent existe dans le texte ; il est textuel. 
Nous appelons cela ``\optword{Endophore}", qui comporte les anaphores et les cataphores. 
Lorsque la référence est contextuelle (elle n'existe pas dans le texte), nous l'appelons ``\optword{Exophore}".
L'exophore est un élément qui ne référence aucun objet ou situation ; il veut dire que la référence ne puisse être connue qu'à base du contexte \cite{2014-halliday-hasan}. 
Dans l'exemple ``\expword{Je vais \underline{là-bas}}", le mot ``là-bas" ne peut être compris si nous somme avec l'interlocuteur. 
Cette référence peut être un endophore si la destination a été mentionnée dans le texte. 
Mais lorsque nous parlons avec quelqu'un, nous n'utilisons pas que la langue parlée ; nous utilisons aussi les signes.

\subsection{Propriétés des relations de coréférence}

Afin de détecter le référent, certaines propriétés comme l'agrément au genre et en nombre avec la référence peuvent être utilisées. 
Quelques traits grammaticaux doivent être identiques pour les deux : référence et référent. 
Ici, nous allons discuter les trois traits qui définissent les pronoms : le nombre, la personne et le genre.
Bien sûr, il existe des langues qui ne supportent pas les trois traits. 
Selon le \optword{nombre}, une entité peut être en : singulier, duel ou pluriel (il existe d'autres formes). 
Dans l'exemple ``\expword{\underline{Les oiseaux} sont sur un arbre. \underline{Ils} chantent}", le pronom ``ils" référence ``les oiseux" puisque les deux sont en pluriel. 
Dans le cas des antécédents partagés, cette propriété va être plus difficile à gérer.
Par exemple, ``\expword{\underline{Le cours} sera suivi par \underline{un exercice}. \underline{Ils} sont importants pour la compréhension.}".
%Il y a aussi le problème des entités singuliers qui sont sémantiquement en pluriel. 
Un autre problème est l'existence des entités singuliers qui réfèrent un groupe d'entités.
Dans leur cas, nous pouvons utiliser le singulier ou le pluriel comme référence. 
Par exemple, l'entreprise ``\expword{IBM}" peut être référencée par ``elle" ou "ils".
%
Selon la \optword{personne}, une entité peut être considérée comme : première, deuxième ou troisième personne. 
En général, la référence et le référent doivent être en agrément en terme de personne.
Exemple,  ``\expword{\underline{Mon frère}\textsubscript{1} et \underline{moi}\textsubscript{2} avons réparé \underline{son vélo}\textsubscript{1} après \underline{le mien}\textsubscript{2}.}".
Mais, nous pouvons trouver des textes où l'interlocuteur utilise la troisième personne à la place de la deuxième pour avoir un effet comique ou pour attirer l'attention de quelqu'un.
%
Selon le \optword{genre}, une entité peut être : masculin, féminin ou neutre. 
Exemple, ``\expword{Lorsque la fille a rencontré son \underline{père}, \underline{il} a été content.}".

En plus des traits grammaticaux, il existe certaines propriétés qui aident la détection du référent (antécédent).
Les  \optword{contraintes de théorie contraignante} sont des contraintes syntaxiques sur la relation mention-antécédent.
Un pronom réfléchi se réfère à l'agent de l'action qui est en général un sujet. 
En français, il peut être conjoint (\expword{me, te, se, nous, vous}) ou disjoint (\expword{moi-même, soi, nous-même, etc.}).
Un exemple en anglais, ``\expword{Janet bought herself a bottle of fish sauce.}". 
Ici, nous savons que ``herself" est une référence vers ``Janet" contrairement au pronom ``her" dans l'exemple ``\expword{Janet bought her a bottle of fish sauce.}".
La \optword{récence} veut dire que les entités mentionnées plus récemment sont plus probables d'être un antécédent.
Exemple, ``\expword{Le médecin a trouvé une vieille carte. Jim a trouvé \underline{une carte} encore plus ancienne. \underline{Elle} décrivait une île.}".
En se basant sur le \optword{rôle grammatical}, les sujets sont plus probables d'être des référents que les objets. 
Exemple, ``\expword{\underline{Karim} est allé au restaurant avec son ami. \underline{Il} a demandé un plat de couscous.}".
La \optword{sémantique du verbe} joue un rôle dans la détection du référent. 
La mention suit l'emphase du verbe ; celui qui a causé l'évènement.
Dans l'exemple ``\expword{\underline{John} telephoned Bill. \underline{He} lost the laptop.}", l'évènement de téléphone a été causé par le sujet ; donc le pronom ``he" revient au sujet. 
Contrairement à l'exemple ``\expword{John criticized \underline{Bill}. \underline{He} lost the laptop.}" où la critique a été causée par l'objet. 
Certes, l'agent ici c'est le sujet ; mais c'est l'objet qui a déclenché l'évènement de critique.

%===================================================================================
\section{Résolution des coréférences}
%===================================================================================

La résolution des coréférences passe par deux étapes : détection de la mention et liaison des coréférences. 
Tout d'abord, il faut détecter les différentes références dans le texte. 
Ensuite, il faut lier ces références avec leurs référents.
Il existe plusieurs modèles de liaison : Mention-Pair, Mention-Rank et Entity-based.
La résolution des coréférences peut être accomplie en suivant une des deux approches : par règles ou par apprentissage automatique. 
Dans cette dernière, nous pouvons nous baser sur des caractéristiques définies manuellement ou par les \keywordpl[E]{embedding}.


\subsection{Détection de mention}

Les mentions sont des entités qui peuvent être des \keywordpl[S]{syntagme} nominaux ou des pronoms.
L'identification des mentions en coréférence est une étape importante dans des tâches de \ac{taln} comme la résolution des coréférences et la reconnaissance des entités nommées.
Cette étape peut être appliquée en utilisant un ensemble des règles ; comme celles définies par \citet{2013-lee-al}.
Nous commençons par marquer les syntagmes nominaux, les pronoms et les entités nommées qui n'ont pas été marqués dans le texte comme des mentions candidates. 
Ensuite, nous sélectionnons les mentions par élimination comme suit :
\begin{itemize}
	\item Nous supprimerions une mention s'il existait une autre mention plus grande ayant la même tête syntaxique. 
	Par exemple, nous devrions supprimer ``\expword{La boite de développement}" si une autre mention plus grande existait ``\expword{La boite de développement située à Alger}". 
	
	\item Il faut écarter les entités numériques telles que les pourcentages, l'argent, les cardinaux et les quantités. 
	Par exemple, ``\expword{9\%}", ``\expword{100\$}", ``\expword{cent neuf}".
	
	\item Nous éliminons les mentions qui sont une partie d'une autre (quantificateur + ``of"). 
	Exemple, ``\expword{a total of 177 projects}", ``\expword{none of them}", ``\expword{millions of people}".
	
	\item Nous supprimons les pronoms qui ne sont pas utilisés comme référence (``it" pléonastique). 
	Dans l'exemple ``\expword{It is thought that ...}", le pronom ``it" n'est pas une référence. 
	Nous pouvons détecter un tel pronom en utilisant une liste des verbes cognitifs (Ex. ``\expword{believe, think, etc.}").
	
	\item Nous éliminons les formes adjectivales des nations ou les acronymes nationales (Ex.,
	``\expword{American}", ``\expword{U.S.}", ``\expword{U.K.}").
\end{itemize}

Une autre méthode pour détecter si une mention est une coréférence ou non est en utilisant l'apprentissage automatique. 
Dans \cite{2013-uryupina-moschitti}, nous commençons par la génération de l'arbre syntaxique d'une phrase. 
Nous parcourons les nœuds et nous classons les syntagmes nominaux comme coréférence ou non en utilisant un SVM. 
Les caractéristiques utilisées sont les propriétés présentées précédemment comme le nombre, le genre, etc.
D'autres systèmes ont été développés, mais ils sont liés à une tâche spécifique et ne peuvent pas être utilisés séparément. 
La figure \ref{fig:det-mention-yu} représente trois architectures de détection des mentions proposées par \citet{2020-yu-al}. 
Étant donné un document $D$, nous commençons par considérer toutes les expressions possibles marquées par le mot du début $w_{si}$ et le mot de fin $w_{ei}$ comme mentions candidates. 
Par exemple, la phrase ``\expword{La boite de développement est loin}" contient $\frac{6 * 7}{2} = 21$ mentions candidates : ``\expword{La}", ``\expword{La boite}", ``\expword{La boite de}", ``\expword{La boite de dévelopement}", ``\expword{La boite de développement est}", ``\expword{La boite de développement est loin}", ``\expword{boite}", ``\expword{boite de}", ``\expword{boite de dévelopement}", ``\expword{boite de développement est}", ``\expword{boite de développement est loin}", ``\expword{de}", ``\expword{de dévelopement}", ``\expword{de développement est}", ``\expword{de développement est loin}",
``\expword{dévelopement}", ``\expword{développement est}", ``\expword{développement est loin}", ``\expword{est}", ``\expword{est loin}" et ``\expword{loin}".
%Système (a)
Le système (a) est un peu plus complexe : chaque mot $w_i$ est représenté par la concaténation de trois embeddings $x_i$  : \keyword[G]{GloVe}, \keyword[E]{ELMo} et un embedding basé sur les caractères en utilisant les CNNs. 
Nous passons la phrase par un réseau \keyword[B]{Bi-LSTM} pour avoir une autre représentation $x_i^*$ qui est la concaténation des deux sorties en avant et en arrière.
Pour représenter une mention $i$ (supposons la 4ième dans la liste passée) par un embedding $h^*_i$, nous appliquons une attention sur $\{x^*_{si}\ldots x^*_{ei}\}$ ; où $si$ et $ei$ sont les indices de début et de la fin de la mention respectivement.
L'attention peut être formulée comme suit (on fixe un nombre maximal des mots dans une mention) :
\begin{align*}
\alpha_t & = FFNN_\alpha(x_t^*) \\
a_{i, t} & = \frac{exp(\alpha_t)}{\sum_{k=si}^{ei} exp(\alpha_k)} \\
h_i^* & = \sum_{t=si}^{ei} a_{i, t} \cdot x_t \\
\end{align*}
La sortie $h^*_i$ est concaténée avec le embedding du mot du début $x^*_{si}$, celui du mot de fin $x^*_{ei}$ et le \keyword[E]{embedding} de la taille de la mention $\phi_i$.
Cette représentation est passée par un réseau de neurones à propagation en avant (FFNN) afin de décider si l'expression est une mention ou non.
% Système b
Dans le système (b), chaque mot est représenté seulement en utilisant \keyword[E]{ELMo} pré-entraîné ; vu que les auteurs ont remarqué que les deux autres représentations n'améliorent pas la tâche.
Ensuite, la phrase est passée par 
Le code de chaque mot est une concaténation des couches cachées du modèle.
Nous utilisons deux réseaux de neurones à propagation avant (FFNN) afin d'encoder le début ($ h_s(i) = FFNN_s(x_{si}^*)$) et la fin ($ h_e(i) = FFNN_e(x_{ei}^*)$) de l'expression $i$ sous forme de deux vecteurs. 
Le début et la fin encodés sont passés par un classifieur Biaffine \cite{2017-dozat-manning} qui rend un score comme suit : 
\begin{align*}
r_m(i) & = h_s(i)^\top W_m h_e + h_s(i) b_m \\
p_m(i) & = \sigma(r_m(i)) \\
\end{align*}
$W_m$ est une matrice de $d\times d$ où $d$ est la taille de l'embedding.
$b_m$ est un vecteur d'une dimension $d$ représentant le biais.
% Système C
Dans le système (c), un modèle \keyword[B]{BERT} pré-entraîné est utilisé afin de générer les représentations des mots $x^*_t$. 
Pour chaque mention candidate $i$ de cette phrase, nous prenons les représentations du début $x^*_{si}$ et de fin $x^*_{ei}$ et les concaténer pour avoir la représentation de l'expression. 
Cette dernière est utilisée comme entrée à un réseau de neurones à propagation avant (FFNN) afin de classer l'expression comme mention ou non. 

\begin{figure}[ht]
	\centering
	\hgraphpage[\textwidth]{mention-detection-arch.pdf}
	\caption[Trois architectures pour la détection des mentions]{Trois architectures pour la détection des mentions ; figure inspirée de \cite{2020-yu-al}}
	\label{fig:det-mention-yu}
\end{figure}

\subsection{Liaison des coréférences}

La liaison des coréférences consiste à lier une référence à son référent. 
En général, cette opération est appelée regroupement des mentions puisque nous regroupons toutes les mentions qui référencent la même entité ensemble. 
Pour ce faire, il y a deux classes des modèles : modèles basés sur les mentions et modèles basés sur les entités. 
Dans ce qui suit, nous allons considérer les coréférences comme des anaphores : mention et antécédent.

\subsubsection{Modèles Mention-Pair}

Nous entraînons un modèle de classement binaire qui prend deux mentions $m_i$ et $m_j$ et rendre une probabilité que $m_i$ est un antécédent de $m_j$ : $P(Coref|m_i, m_j)$. 
Les caractéristiques utilisées peuvent être des propriétés des deux mentions comme la personne, le genre, le nombre, etc.
Afin de détecter les coréférences, le modèle est appliqué deux à deux.
Dans la figure \ref{fig:mention-pair-exp}, le modèle doit estimer une grande probabilité P(coref| ``Victoria Chen", ``she") et une petite probabilité P(coref| ``Megabucks Banking", ``she").
Ici, le mot ``she" est lié avec plusieurs mots sans prendre en considération de leurs relations.

\begin{figure}[ht]
	\centering
	\hgraphpage[.8\textwidth]{mention-pair-exp.pdf}
	\caption[Exemple d'un modèle Mention-Pair]{Exemple d'un modèle Mention-Pair ; figure reconstruite de \cite{2019-jurafsky-martin}}
	\label{fig:mention-pair-exp}
\end{figure}

Afin d'entraîner le modèle, nous utilisons toutes les combinaisons binaires possibles.
Le problème est que nous allons avoir plusieurs exemples négatifs ; un dataset déséquilibré. 
Une solution est de ne prendre en considération que les mentions négatives qui se trouvent entre deux mentions positives.

\subsubsection{Modèles Mention-Rank}

Ce modèle est similaire au modèle Mention-Pair dans le fait que nous comparons les mentions deux à deux. 
Mais, la différence est que celui-ci apprenne à classer les antécédents ; il apprend une sorte d'ordre. 
Dans ce cas, nous utilisons des différentes caractéristiques sur la référence $m_i$ et l'antécédent $m_j$ afin d'estimer une probabilité conditionnelle $P(m_j|m_i)$.
Donc, la tâche consiste à maximiser la probabilité qu'une mention est un antécédent $\hat{a}$ comme indiqué dans l'équation \ref{eq:mention-rank} où $\epsilon$ veut dire la mention n'a pas d'antécédent. 
\begin{equation}\label{eq:mention-rank}
\hat{a} = \arg\max_{j \in \{\epsilon, 1, \ldots, (i-1)\}} P(w_j|w_i) 
\end{equation}
Dans l'étape d'entraînement, nous devons choisir un seul exemple positif parmi ceux possibles. 
Une approche consiste à prendre la mention la plus proche.
Une fois un antécédent est détecté, le reste des antécédents sont détectés en utilisant la transitivité. 
La figure \ref{fig:mention-rank-exp} représente un exemple de l'annotation Mention-Rank.
Dans cette exemple si nous choisissions ``Victoria Chen" comme antécédent du pronom ``she", nous devrions ignorer le reste des grandes probabilités (ligne continue).
Cela nous assure qu'il n'aura pas des coréférences contradictoires.
\begin{figure}[ht]
	\centering
	\hgraphpage[.8\textwidth]{mention-rank-exp.pdf}
	\caption[Exemple d'un modèle Mention-Rank]{Exemple d'un modèle Mention-Rank ; figure reconstruite de \cite{2019-jurafsky-martin}}
	\label{fig:mention-rank-exp}
\end{figure}



\subsubsection{Modèles Entity-based}

Le problème des modèles basés sur la mention est qu'ils comparent les mentions deux à deux ; ils ne prennent pas la relation avec les autres coréférences en considération.
Par exemple, \expword{Ms Kennedy $ \leftarrow $ Kennedy, Kennedy $ \leftarrow $ He}.
Dans ces modèles, la coréférence est considérée comme un problème de classement ; or elle doit être considérée comme un problème de regroupement (clustering). 
Une des méthodes est d'appliquer Mention-Rank sur des clusters et pas sur des entités. 
Nous commençons par la création des clusters d'une seule mention. 
Étant donné deux clusters des mentions, nous vérifions si les deux sont compatibles en utilisant un algorithme d'apprentissage.
Afin de représenter chaque cluster, nous pouvons utiliser des RNN sur les mentions.
Nous pouvons, aussi, utiliser les caractéristiques des mentions comme le genre, le nombre, etc.
En utilisant le modèle entraîné, nous vérifions les clusters deux à deux pour décider s'ils sont compatibles ou non.
Si les clusters sont compatibles, nous les fusionnons et nous appliquons la même opération jusqu'à ce que les clusters restants ne sont plus compatibles.

\section{Évaluation}

Il existe plusieurs métriques pour évaluer la résolution des coréférences \cite{2016-moosavi-strube}.
Dans \optword{MUC} (Message Understanding Conference), l'évaluation est basée sur le nombre des liens binaires communs entre la référence et le système.
Le corpus de test contient un texte et un ensemble de tous les liens binaires possibles. 
Cette métrique favorise les systèmes avec des chaînes larges. 
Aussi, elle ne prend pas en considération les singletons (les mentions sans antécédent).

\optword{B\textsuperscript{3}} est une métrique basée sur les mentions (mention-based metric). 
Le rappel et la précision globaux sont calculés en terme des rappels et précisions locaux par rapport à une chaîne de mentions. 
Supposant que nous avons un nombre des clusters de mentions destinataires (hypothèse), nous annotons $H_i$ le cluster contenant la mention $m_i$. 
Donc, le cluster contenant la mention $m_i$ selon le système est annoté $S_i$. 
Si nous avons $N$ mentions, le rappel peut être calculé en utilisant le nombre des mentions en commun comme indiqué dans l'équation \ref{eq:b3-r} où $w_i$ est un poids attribué à la mention $w_i$. 
\begin{equation}\label{eq:b3-r}
R = \sum_{i=1}^{N} w_i \frac{|H_i \bigcap S_i|}{|H_i|}
\end{equation}

\optword{CEAF} (Constrained entity-alignment F-Measure) utilise chaque mention une seule fois lors du calcul. 
Pour ce faire, elle aligne une entité (cluster de mentions) $S_i$ du système avec une autre entité $H_j$ d'hypothèse (annotation manuelle) en utilisant une mesure de similarité. 
Deux mesures de similarité ont été utilisées dans les équations \ref{eq:ceaf1}.
\begin{equation}\label{eq:ceaf1}
\phi_1(H_i, S_j) = |H_i \cap S_i | \quad \phi_2(H_i, S_j) = \frac{2|H_i \cap S_i | }{|H_i| + |S_j|}
\end{equation}
Pour calculer le rappel, nous cherchons les clusters qui sont les plus similaires selon une fonction de similarité $\phi$ (voir l'équation \ref{eq:ceaf-r}).
\begin{equation}\label{eq:ceaf-r}
R = \frac{\max_{i,j} \phi(H_i, S_j)}{\sum_i \phi(H_i, H_i)}
\end{equation}


\optword{BLANC} (BiLateral assessment of noun-phrase coreference) est une métrique basée sur les liens (link-based metric). 
Le rappel (précision) globale est la moyenne des rappels (précisions) des liens de coréférences et ceux des non coréférences. 
Les liens de coréférence sont représentées comme un tuple (référence, référent).
Donc, étant donné un nombre $N$ de mentions, nous aurons $N (N+1)/2$ liens de coréférences possibles. 
Le tableau \ref{tab:blanc-confusion} représente la matrice de confusion de BLANC où ``w" veut dire ``wrong", ``r" veut dire ``right", ``c" veut dire ``coreference" et ``n" veut dire ``Non-coreference".
Dans ce cas, le rappel est calculé selon l'équation \ref{eq:blanc-r}.
\begin{equation}\label{eq:blanc-r}
R_c = \frac{rc}{rc+wn},\quad R_n = \frac{rn}{rn+wc},\quad R = \frac{R_c + R_n}{2}
\end{equation}

\begin{table}[ht]
	\centering 
	\begin{tabular}{llll}
%		\hline\hline
		\cline{3-4}\noalign{\vskip\doublerulesep
			\vskip-\arrayrulewidth}\cline{3-4}
		&& \multicolumn{2}{c}{Système} \\
		\cline{3-4}
	    && Coréf & Non-Coréf  \\
	    \cline{1-2}\noalign{\vskip\doublerulesep
	    	\vskip-\arrayrulewidth}\hline
	    
	\multirow{2}{*}{Hypothèse} & Coréf & rc & wn \\
	                       & Non-Coréf & wc & rn \\
	   \hline\hline
	\end{tabular}
	\caption[Matrice de confusion de BLANC]{Matrice de confusion de BLANC \cite{2011-recasens-hovy}}
	\label{tab:blanc-confusion}
\end{table}

\optword{LEA} (Link based entity aware) vise à représenter le rappel et la précision en terme de l'importance d'une entité et comment elle a été résolue. 
La taille d'une entité (nombre des mentions dans le cluster) est considéré comme mesure de son importance. 
La proportion du nombre des liens des mentions partagées entre l'hypothèse et le système par rapport le nombre des liens des mentions de l'hypothèse est considérée comme mesure de qualité de résolution. 
Donc, le rappel sera calculé comme indiqué dans l'équation \ref{eq:lea-r} où $link$ compte le nombre des liens dans un cluster.
\begin{equation}\label{eq:lea-r}
R = \frac{\sum_{H_i} (|H_i| \times \sum_{S_j} \frac{link(H_i \bigcup S_j)}{H_i})}{\sum_{H_k} link(H_k)}
\end{equation}

%===================================================================================
\section{Tâches connexes}
%===================================================================================

Afin d'accomplir la tâche de détection de la coréférence, il existe des tâches de prétraitement vues dans le chapitre 2, comme la tâche de segmentation du texte. 
Une autre tâche utile pour détecter les coréférences est l'étiquetage morpho-syntaxique vue dans le chapitre 4.
L'analyse syntaxique (chapitre 5) peut être utilisée pour détecter les syntagmes nominaux. 
Les entités nommées sont un critère important dans la résolution des coréférences.
La tâche de reconnaissance des entités nommées sera discutée brièvement dans cette section.

Il existe des tâches similaires à celle de la résolution des coréférences qui visent à chercher un référent d'une référence dans un texte donné. 
Il existe des références qui ont besoin de plus de contexte afin de comprendre le texte (niveau pragmatique). 
Pour ce faire, il existe une tâche appelée annotation sémantique (Entity linking) qui vise à lier des mentions avec des entités d'une base de connaissance. 
Une autre tâche moins similaire est l'attribution de la citation qui vise à trouver qui a dit/écrit un discours. 
C'est une sorte de classification où les classes représentent une liste des auteurs/personnes.


\subsection{Annotation sémantique (Entity linking)}

L'objectif de l'annotation sémantique est d'associer une mention dans un texte à une représentation d'une entité dans une base de connaissances structurée. 
Cette tâche est motivée par le fait d'avoir une connaissance approfondie sur les entités du texte dans le monde réel (contexte, niveau pragmatique).
Cette tâche est liée à la base de connaissance utilisée ; lorsque nous utilisons Wikipédia comme base de connaissance, nous appelons cette tâche ``Wikification".

Avant d'appliquer cette étape, nous devons détecter les mentions dans le texte (comme dans la résolution des coréférences).
Afin d'annoter une mention du texte, nous suivons deux étapes :
\begin{itemize}
	\item \optword{Détection de la mention} : détecter l'ensemble des entités d'une base de connaissance liées à une mention en utilisant des requêtes.
	Vu que la base est structurée, la recherche sera facile ; dans Wikipedia, nous utilisons les titres.
	\item \optword{Désambigüisation de la mention} : trouver l'entité la plus probable en utilisant l'apprentissage automatique. 
	Comme caractéristiques, nous prenons celles de la mention et celles de l'entité.
\end{itemize}

\subsection{Reconnaissance des entités nommées}

Une entité nommée peut être une personne, une place, une organisation, une quantité, etc.
La tâche de reconnaissance des entités nommées consiste à localiser et classer les entités nommées dans un texte. 
En anglais, elle est appelée ``Named-entity recognition" (NER). 
La localisation se fait en utilisant la détection de mention vue précédemment dans ce chapitre.
Afin de classer les mentions, nous pouvons utiliser plusieurs approches :
\begin{itemize}
	\item \optword{Règles} : utiliser des règles et des listes de noms pour chercher les entités et détecter leurs types.
	\item \optword{Apprentissage avec caractéristiques} : utiliser les \keywordpl[E]{embedding} du mot et ses voisins, les préfixes et les suffixes, l'appartenance à une liste, etc.
	\item \optword{Étiquetage de séquences} : classer les mots en entités en les traitant comme une séquence en utilisant \keyword[I]{IOB} vue dans le chapitre 4.
	
	\expword{
		$ \underbrace{Google}_{B-ORG} $ 
		$ \underbrace{LLC}_{I-ORG} $ 
		$ \underbrace{est}_{O} $ 
		$ \underbrace{fond\text{\textit{é}}e}_{O} $ 
		$ \underbrace{dans}_{O} $ 
		$ \underbrace{la}_{O} $ 
		$ \underbrace{Silicon}_{B-LOC} $ 
		$ \underbrace{Valley}_{I-LOC} $ 
		$ \underbrace{par}_{O} $ 
		$ \underbrace{Larry}_{B-PER} $ 
		$ \underbrace{Page}_{I-PER} $ 
		$ \underbrace{et}_{O} $ 
		$ \underbrace{Sergey}_{B-PER} $ 
		$ \underbrace{Brin}_{I-PER} $
	}
\end{itemize}



%\begin{discussion}
\sectioni{Discussion}
Beaucoup de langues considèrent la répétition comme une forme non naturelle. 
A notre connaissance, nous ne savons pas s'il existe des langues où nous devons répéter les entités dans chaque phrase. 
L'être humain a la capacité de détecter le référent (celui qui a été référencé) facilement. 
Bien sûr, il existe des cas où les références sont tellement ambigües, nous ne pouvons pas les résoudre naturellement. 
Il sera vraiment bénéfique si une machine peut exécuter cette tâche. 
Puisque les pronoms ne sont pas les seules références, cette tâche doit passer par une étape de détection des mentions. 

Deux approches sont utilisées pour la liaison des coréférences : les modèles basés sur les mentions et les modèles basés sur les entités. 
En se basant sur les mentions, nous essayons de trouver les relations deux à deux.
Cela peut causer un problème d'incompatibilité entre les mentions d'une chaîne. 
Les modèles basés sur les entités cherchent à regrouper les mentions compatibles ensembles ; c'est une tâche de regroupement (clustering). 
Malgré que l'utilisation des entités peut éviter le problème d'incompatibilité, l'approche basée sur les mentions est plus utilisée vu la facilité de son implémentation. 

Cette tâche est une sorte de classification, donc nous pouvons utiliser le rappel, la précision et le F-score pour l'évaluer. 
Mais, comme le problème peut être vu comme des liens ou des entités, ces mesures peuvent être formulées de plusieurs façons. 
Plusieurs mesures ont été présentées dans ce chapitre, ainsi que des tâches similaires à la  résolution des coréférences.
%\end{discussion}

\sectioni{Ressources supplémentaires}

\subsubsection*{Exercices}

\begin{enumerate}
	\item Voici un texte :
	
	\begin{tabular}{|p{0.9\textwidth}|}
		\hline
		La fille a cueilli une fleur. 
		Elle l'a sentie. 
		Elle a une très bonne odeur.
		Cette belle fleur est dans l'école nationale supérieure d'informatique où la fille étudie.
		L'ESI se situe à Alger ; une ville dans le nord de l'Algérie.\\
		\hline
	\end{tabular}

	\begin{enumerate}
		\item Trouver toutes les mentions en indiquant les formes de références.
		\item Annoter les co-références.
		\item Écrire une procédure qui prend deux mentions comme arguments et rendre un booléen indiquant si le premier est un antécédent du deuxième en se basant sur les propriétés des deux.
		\item Appliquer l'algorithme Mention-Pair avec cette procédure sur les mentions de la première question et vérifier si les co-références générées sont similaires à celles manuellement annotées.
		\item Écrire une procédure qui prend deux mentions avec un tableau des mentions entre les deux comme arguments et rendre un score indiquant si le premier est un antécédent du deuxième en se basant sur les propriétés des deux.
		\item Appliquer l'algorithme Mention-Rank avec cette procédure sur les mentions de la première question et vérifier si les co-références générées sont similaires à celles manuellement annotées.
		\item Écrire une procédure récursive qui implémente un modèle Entity-based. Cette procédure prend un ensemble des clusters comme argument et rend un autre ensemble de clusters. 
	\end{enumerate}

	
\end{enumerate}

\subsubsection*{Tutoriels}

Les tutoriels sont accessibles via le répertoire Github.
Le tutoriel présente comment utiliser Stanford CoreNLP (java) pour chercher les coréférences.
%Le deuxième concerne l'utilisation de neuralcoref avec spaCy (python) pour la même tâche.

%\subsubsection*{TP : Analyse syntaxique CKY}

%\subsubsection*{Lab}

%=====================================================================
\ifx\wholebook\relax\else
% \cleardoublepage
% \bibliographystyle{../use/ESIbib}
% \bibliography{../bib/RATstat}
	\end{document}
\fi
%=====================================================================
