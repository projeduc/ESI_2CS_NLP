{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f7f433",
   "metadata": {},
   "source": [
    "# Text preprocessing using OpenNLP\n",
    "\n",
    "Downloading the api from maven repository may take some time. \n",
    "You can find models in this link: https://opennlp.apache.org/models.html \n",
    "Sourceforge models can be downloaded here: http://opennlp.sourceforge.net/models-1.5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1927a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pom\n",
    "dependencies:\n",
    "    - org.apache.opennlp:opennlp-tools:1.9.3\n",
    "\n",
    "#you can use this with maven\n",
    "#<dependency>\n",
    "#    <groupId>org.apache.opennlp</groupId>\n",
    "#    <artifactId>opennlp-tools</artifactId>\n",
    "#    <version>1.9.3</version>\n",
    "#</dependency>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b72c2",
   "metadata": {},
   "source": [
    "## I. Language detection\n",
    "\n",
    "### I.1. Detection using a trained model\n",
    "Here, we will use **langdetect** model found in https://opennlp.apache.org/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399fa0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "A computer is a machine that can be programmed to carry out sequences of arithmetic or logical operations automatically.\n",
      "Best language: eng\n",
      "Best language confidence: 0.13386670528129072\n",
      "----------------------------------------------------\n",
      "Un ordinateur est un système de traitement de l'information programmable tel que défini par Alan Turing et qui fonctionne par la lecture séquentielle d'un ensemble d'instructions.\n",
      "Best language: fra\n",
      "Best language confidence: 0.3152233825312163\n",
      "----------------------------------------------------\n",
      "La computadora también denominada computador​ u ordenador es una máquina digital programable que ejecuta una serie de comandos para procesar los datos de entrada, obteniendo convenientemente información que posteriormente se envía a las unidades de salida.\n",
      "Best language: spa\n",
      "Best language confidence: 0.43167282617777747\n",
      "----------------------------------------------------\n",
      "الحَاسُوب هو آلة إلكترونية لها قابلية استقبال البيانات ومعالجتها إلى معلومات ذات قيمة.\n",
      "Best language: ara\n",
      "Best language confidence: 0.09672794809617366\n",
      "----------------------------------------------------\n",
      "رایانِه یا کامپیوتِر دستگاهی الکترونیک است که می‌تواند برنامه‌ریزی شود تا دستور های ریاضیاتی و منطقی را به‌صورت خودکاره از طریق برنامه‌نویسی انجام دهد.\n",
      "Best language: pes\n",
      "Best language confidence: 0.2786595136074614\n",
      "----------------------------------------------------\n",
      "コンピュータは、主にトランジスタを含む電子回路を応用し、数値計算、情報処理、データ処理、文書作成、動画編集、遊戯など、複雑な（広義の）計算を高速、大量におこなうことを目的として開発された機械である。\n",
      "Best language: jpn\n",
      "Best language confidence: 0.0634284778467308\n",
      "----------------------------------------------------\n",
      "电子计算机是利用数字电子技术，根据一系列指令指示並且自动执行任意算术或逻辑操作序列的设备。\n",
      "Best language: cmn\n",
      "Best language confidence: 0.028383704387085297\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "import java.io.*;\n",
    "import opennlp.tools.langdetect.*;\n",
    "\n",
    "String[] texts = new String[]{\n",
    "    \"A computer is a machine that can be programmed to carry out sequences of arithmetic or logical operations automatically.\",\n",
    "    \"Un ordinateur est un système de traitement de l'information programmable tel que défini par Alan Turing et qui fonctionne par la lecture séquentielle d'un ensemble d'instructions.\",\n",
    "    \"La computadora también denominada computador​ u ordenador es una máquina digital programable que ejecuta una serie de comandos para procesar los datos de entrada, obteniendo convenientemente información que posteriormente se envía a las unidades de salida.\",\n",
    "    \"الحَاسُوب هو آلة إلكترونية لها قابلية استقبال البيانات ومعالجتها إلى معلومات ذات قيمة.\",\n",
    "    \"رایانِه یا کامپیوتِر دستگاهی الکترونیک است که می‌تواند برنامه‌ریزی شود تا دستور های ریاضیاتی و منطقی را به‌صورت خودکاره از طریق برنامه‌نویسی انجام دهد.\",\n",
    "    \"コンピュータは、主にトランジスタを含む電子回路を応用し、数値計算、情報処理、データ処理、文書作成、動画編集、遊戯など、複雑な（広義の）計算を高速、大量におこなうことを目的として開発された機械である。\",\n",
    "    \"电子计算机是利用数字电子技术，根据一系列指令指示並且自动执行任意算术或逻辑操作序列的设备。\",\n",
    "};\n",
    "//english, french, spanish, arabic, persian, japanese, chinese\n",
    "    \n",
    "try{\n",
    "    InputStream modelIn = new FileInputStream(\"/home/kariminf/Data/OpenNLP/langdetect-183.bin\");\n",
    "    LanguageDetectorModel model = new LanguageDetectorModel(modelIn);\n",
    "    LanguageDetectorME detecter = new LanguageDetectorME(model);\n",
    "    for (String text: texts){\n",
    "        System.out.println(\"----------------------------------------------------\");\n",
    "        System.out.println(text);\n",
    "        Language bestLanguage = detecter.predictLanguage(text);\n",
    "        System.out.println(\"Best language: \" + bestLanguage.getLang());\n",
    "        System.out.println(\"Best language confidence: \" + bestLanguage.getConfidence());\n",
    "    }\n",
    "}\n",
    "catch(IOException e){\n",
    "    System.out.println(\"Model not found!\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba56b1",
   "metadata": {},
   "source": [
    "### I.2. Training a model\n",
    "Let's build a model to detect numeral systems: binary (BIN), Decimal (DEC) and Hexadecimal (HEX). In the training file, each line contains an exemple of a language starting with the language code followed by a tabulation followed by the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bf60a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing events with OnePass using cutoff of 5\n",
      "\n",
      "\tComputing event counts...  done. 20 events\n",
      "\tIndexing...  Dropped event BIN:[]\n",
      "Dropped event BIN:[]\n",
      "Dropped event BIN:[]\n",
      "Dropped event BIN:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event DEC:[]\n",
      "Dropped event HEX:[]\n",
      "Dropped event HEX:[d]\n",
      "Dropped event HEX:[f]\n",
      "done.\n",
      "Sorting and merging events... done. Reduced 5 events to 1.\n",
      "Done indexing in 0.00 s.\n",
      "Incorporating indexed data for training...  \n",
      "done.\n",
      "\tNumber of Event Tokens: 1\n",
      "\t    Number of Outcomes: 3\n",
      "\t  Number of Predicates: 1\n",
      "...done.\n",
      "Computing model parameters ...\n",
      "Performing 100 iterations.\n",
      "  1:  ... loglikelihood=-5.493061443340549\t0.0\n",
      "  2:  ... loglikelihood=-2.5541281188299547\t1.0\n",
      "  3:  ... loglikelihood=-1.6823611831060645\t1.0\n",
      "  4:  ... loglikelihood=-1.2565721414045303\t1.0\n",
      "  5:  ... loglikelihood=-1.0033534773107562\t1.0\n",
      "  6:  ... loglikelihood=-0.8352704233158316\t1.0\n",
      "  7:  ... loglikelihood=-0.7155042182033672\t1.0\n",
      "  8:  ... loglikelihood=-0.6258157147700307\t1.0\n",
      "  9:  ... loglikelihood=-0.5561281755511225\t1.0\n",
      " 10:  ... loglikelihood=-0.5004172927849133\t1.0\n",
      " 11:  ... loglikelihood=-0.4548588910286338\t1.0\n",
      " 12:  ... loglikelihood=-0.41690804469525505\t1.0\n",
      " 13:  ... loglikelihood=-0.38480520568064164\t1.0\n",
      " 14:  ... loglikelihood=-0.35729481991072487\t1.0\n",
      " 15:  ... loglikelihood=-0.3334568724933614\t1.0\n",
      " 16:  ... loglikelihood=-0.3126017849066703\t1.0\n",
      " 17:  ... loglikelihood=-0.2942025001146673\t1.0\n",
      " 18:  ... loglikelihood=-0.27784925577405384\t1.0\n",
      " 19:  ... loglikelihood=-0.26321866742711014\t1.0\n",
      " 20:  ... loglikelihood=-0.2500521028733071\t1.0\n",
      " 21:  ... loglikelihood=-0.23814024494627353\t1.0\n",
      " 22:  ... loglikelihood=-0.227311870383787\t1.0\n",
      " 23:  ... loglikelihood=-0.21742555969869445\t1.0\n",
      " 24:  ... loglikelihood=-0.20836348200284038\t1.0\n",
      " 25:  ... loglikelihood=-0.20002667306849625\t1.0\n",
      " 26:  ... loglikelihood=-0.19233140413898087\t1.0\n",
      " 27:  ... loglikelihood=-0.18520635840174607\t1.0\n",
      " 28:  ... loglikelihood=-0.17859041301039671\t1.0\n",
      " 29:  ... loglikelihood=-0.1724308803558472\t1.0\n",
      " 30:  ... loglikelihood=-0.1666821013379592\t1.0\n",
      " 31:  ... loglikelihood=-0.16130431109110777\t1.0\n",
      " 32:  ... loglikelihood=-0.15626271752052268\t1.0\n",
      " 33:  ... loglikelihood=-0.15152674747664518\t1.0\n",
      " 34:  ... loglikelihood=-0.14706942603146728\t1.0\n",
      " 35:  ... loglikelihood=-0.14286686222028058\t1.0\n",
      " 36:  ... loglikelihood=-0.1388978205353791\t1.0\n",
      " 37:  ... loglikelihood=-0.13514336193959686\t1.0\n",
      " 38:  ... loglikelihood=-0.13158654158686767\t1.0\n",
      " 39:  ... loglikelihood=-0.12821215306668893\t1.0\n",
      " 40:  ... loglikelihood=-0.12500651102708693\t1.0\n",
      " 41:  ... loglikelihood=-0.1219572656207962\t1.0\n",
      " 42:  ... loglikelihood=-0.11905324346859336\t1.0\n",
      " 43:  ... loglikelihood=-0.11628431082133675\t1.0\n",
      " 44:  ... loglikelihood=-0.11364125538778087\t1.0\n",
      " 45:  ... loglikelihood=-0.11111568392355176\t1.0\n",
      " 46:  ... loglikelihood=-0.10869993318202995\t1.0\n",
      " 47:  ... loglikelihood=-0.10638699223642482\t1.0\n",
      " 48:  ... loglikelihood=-0.10417043451421013\t1.0\n",
      " 49:  ... loglikelihood=-0.10204435815603562\t1.0\n",
      " 50:  ... loglikelihood=-0.10000333353334771\t1.0\n",
      " 51:  ... loglikelihood=-0.09804235694188157\t1.0\n",
      " 52:  ... loglikelihood=-0.09615680963943767\t1.0\n",
      " 53:  ... loglikelihood=-0.09434242152191402\t1.0\n",
      " 54:  ... loglikelihood=-0.09259523883618764\t1.0\n",
      " 55:  ... loglikelihood=-0.09091159541595237\t1.0\n",
      " 56:  ... loglikelihood=-0.08928808700003231\t1.0\n",
      " 57:  ... loglikelihood=-0.08772154825454753\t1.0\n",
      " 58:  ... loglikelihood=-0.08620903217253051\t1.0\n",
      " 59:  ... loglikelihood=-0.0847477915688666\t1.0\n",
      " 60:  ... loglikelihood=-0.0833352624260588\t1.0\n",
      " 61:  ... loglikelihood=-0.08196904887838191\t1.0\n",
      " 62:  ... loglikelihood=-0.08064690964941822\t1.0\n",
      " 63:  ... loglikelihood=-0.07936674578145061\t1.0\n",
      " 64:  ... loglikelihood=-0.07812658951540435\t1.0\n",
      " 65:  ... loglikelihood=-0.07692459419739728\t1.0\n",
      " 66:  ... loglikelihood=-0.07575902510301111\t1.0\n",
      " 67:  ... loglikelihood=-0.07462825108337853\t1.0\n",
      " 68:  ... loglikelihood=-0.07353073694847724\t1.0\n",
      " 69:  ... loglikelihood=-0.07246503651283433\t1.0\n",
      " 70:  ... loglikelihood=-0.0714297862373827\t1.0\n",
      " 71:  ... loglikelihood=-0.07042369940869486\t1.0\n",
      " 72:  ... loglikelihood=-0.06944556080333575\t1.0\n",
      " 73:  ... loglikelihood=-0.06849422179080958\t1.0\n",
      " 74:  ... loglikelihood=-0.0675685958336141\t1.0\n",
      " 75:  ... loglikelihood=-0.06666765434732629\t1.0\n",
      " 76:  ... loglikelihood=-0.06579042288755599\t1.0\n",
      " 77:  ... loglikelihood=-0.06493597763405595\t1.0\n",
      " 78:  ... loglikelihood=-0.06410344214530717\t1.0\n",
      " 79:  ... loglikelihood=-0.06329198435961732\t1.0\n",
      " 80:  ... loglikelihood=-0.06250081382115748\t1.0\n",
      " 81:  ... loglikelihood=-0.0617291791114969\t1.0\n",
      " 82:  ... loglikelihood=-0.06097636546909178\t1.0\n",
      " 83:  ... loglikelihood=-0.06024169258087297\t1.0\n",
      " 84:  ... loglikelihood=-0.05952451253159213\t1.0\n",
      " 85:  ... loglikelihood=-0.05882420789793185\t1.0\n",
      " 86:  ... loglikelihood=-0.058140189975595495\t1.0\n",
      " 87:  ... loglikelihood=-0.05747189712867567\t1.0\n",
      " 88:  ... loglikelihood=-0.056818793251575475\t1.0\n",
      " 89:  ... loglikelihood=-0.05618036633462921\t1.0\n",
      " 90:  ... loglikelihood=-0.055556127125354175\t1.0\n",
      " 91:  ... loglikelihood=-0.05494560787797603\t1.0\n",
      " 92:  ... loglikelihood=-0.0543483611845194\t1.0\n",
      " 93:  ... loglikelihood=-0.05376395888130925\t1.0\n",
      " 94:  ... loglikelihood=-0.05319199102527877\t1.0\n",
      " 95:  ... loglikelihood=-0.05263206493493752\t1.0\n",
      " 96:  ... loglikelihood=-0.052083804291278575\t1.0\n",
      " 97:  ... loglikelihood=-0.05154684829430719\t1.0\n",
      " 98:  ... loglikelihood=-0.051020850871209236\t1.0\n",
      " 99:  ... loglikelihood=-0.05050547993252022\t1.0\n",
      "100:  ... loglikelihood=-0.05000041667291767\t1.0\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "import java.io.*;\n",
    "import opennlp.tools.langdetect.*;\n",
    "import opennlp.tools.util.*;\n",
    "import java.nio.charset.StandardCharsets;\n",
    "import opennlp.tools.util.model.ModelUtil;\n",
    "\n",
    "// Read file with greetings in many languages\n",
    "InputStreamFactory inputStreamFactory = new MarkableFileInputStreamFactory(new File(\"num.txt\"));\n",
    "ObjectStream<String> lineStream = new PlainTextByLineStream(inputStreamFactory, StandardCharsets.UTF_8);\n",
    "ObjectStream<LanguageSample> sampleStream = new LanguageDetectorSampleStream(lineStream);\n",
    " \n",
    "// Train a model from the greetings with many languages.\n",
    "LanguageDetectorModel model = LanguageDetectorME.train(sampleStream,\n",
    "    ModelUtil.createDefaultTrainingParameters(), new LanguageDetectorFactory());\n",
    " \n",
    "// Serialize model to some file so that next time we don't have to again train a\n",
    "// model. Next time We can just load this file directly into model.\n",
    "//model.serialize(new File(\"num.bin\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488594d",
   "metadata": {},
   "source": [
    "## II. Sentence boundary detection\n",
    "\n",
    "### II.1. Detection using a model\n",
    "\n",
    "Here, we will use English sentence detection model found in https://opennlp.apache.org/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85507d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a text written by Mr. Aries.\n",
      "It uses U.S. english to illustrate sentence tokenization.\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "import java.io.*;\n",
    "import opennlp.tools.sentdetect.*;\n",
    "\n",
    "String text = \"This is a text written by Mr. Aries. It uses U.S. english to illustrate sentence tokenization.\";\n",
    "    \n",
    "try{\n",
    "    InputStream modelIn = new FileInputStream(\"/home/kariminf/Data/OpenNLP/opennlp-en-ud-ewt-sentence-1.0-1.9.3.bin\");\n",
    "    SentenceModel model = new SentenceModel(modelIn);\n",
    "    SentenceDetectorME detecter = new SentenceDetectorME(model);\n",
    "    String sentences[] = detecter.sentDetect(text);\n",
    "    for (String sentence: sentences){\n",
    "        System.out.println(sentence);\n",
    "    }\n",
    "    \n",
    "}\n",
    "catch(IOException e){\n",
    "    System.out.println(\"Model not found!\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a7524",
   "metadata": {},
   "source": [
    "### II.2. Training a model\n",
    "Let's build a model to detect sentences boundaries. In the training file, each line represents a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f609b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing events with TwoPass using cutoff of 5\n",
      "\n",
      "\tComputing event counts...  done. 7 events\n",
      "\tIndexing...  done.\n",
      "Sorting and merging events... done. Reduced 7 events to 3.\n",
      "Done indexing in 0.00 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "jdk.jshell.EvalException: Training data must contain more than one outcome\n",
      "\tat opennlp.tools.ml.AbstractEventTrainer.train(AbstractEventTrainer.java:78)\n",
      "\tat opennlp.tools.ml.AbstractEventTrainer.train(AbstractEventTrainer.java:93)\n",
      "\tat opennlp.tools.sentdetect.SentenceDetectorME.train(SentenceDetectorME.java:325)\n",
      "\tat opennlp.tools.sentdetect.SentenceDetectorME.train(SentenceDetectorME.java:310)\n",
      "\tat .(#385:1)\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "import java.io.*;\n",
    "import opennlp.tools.sentdetect.*;\n",
    "import opennlp.tools.util.*;\n",
    "import java.nio.charset.StandardCharsets;\n",
    "\n",
    "// read the sentences file\n",
    "InputStreamFactory inputStreamFactory = new MarkableFileInputStreamFactory(new File(\"en-sent.txt\"));\n",
    "ObjectStream<String> lineStream = new PlainTextByLineStream(inputStreamFactory, StandardCharsets.UTF_8);\n",
    "\n",
    "SentenceModel model;\n",
    "\n",
    "try (ObjectStream<SentenceSample> sampleStream = new SentenceSampleStream(lineStream)) {\n",
    "  model = SentenceDetectorME.train(\"en\", sampleStream, true, null, TrainingParameters.defaultParams());\n",
    "}\n",
    "\n",
    "\n",
    "try (OutputStream modelOut = new BufferedOutputStream(new FileOutputStream(\"en-detect.bin\"))) {\n",
    "  model.serialize(modelOut);\n",
    "}\n",
    "\n",
    "//TODO fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd4b57",
   "metadata": {},
   "source": [
    "## III. Word tokenization\n",
    "Here, we will use English words tokenization model found in https://opennlp.apache.org/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99807e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This | is | a | text | written | by | Mr. | Aries | . | It | uses | U.S. | english | to | illustrate | sentence | tokenization | . | "
     ]
    }
   ],
   "source": [
    "%%java\n",
    "import java.io.*;\n",
    "import opennlp.tools.tokenize.*;\n",
    "\n",
    "String text = \"This is a text written by Mr. Aries. It uses U.S. english to illustrate sentence tokenization.\";\n",
    "    \n",
    "try{\n",
    "    InputStream modelIn = new FileInputStream(\"/home/kariminf/Data/OpenNLP/opennlp-en-ud-ewt-tokens-1.0-1.9.3.bin\");\n",
    "    TokenizerModel model = new TokenizerModel(modelIn);\n",
    "    Tokenizer tokenizer = new TokenizerME(model);\n",
    "    String words[] = tokenizer.tokenize(text);\n",
    "    for (String word: words){\n",
    "        System.out.print(word + \" | \");\n",
    "    }\n",
    "    \n",
    "}\n",
    "catch(IOException e){\n",
    "    System.out.println(\"Model not found!\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IV. Word tokenization\n",
    "Here, we will use English words tokenization model found in https://opennlp.apache.org/models.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ganymede 1.1.0.20210614 (Java 17)",
   "language": "java",
   "name": "ganymede-1.1.0.20210614-java-17"
  },
  "language_info": {
   "file_extension": ".java",
   "mimetype": "text/x-java",
   "name": "java",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
