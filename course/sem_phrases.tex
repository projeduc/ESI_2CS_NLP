% !TEX TS-program = xelatex
% !TeX program = xelatex
% !TEX encoding = UTF-8
% !TEX spellcheck = fr

%=====================================================================
\ifx\wholebook\relax\else
	\documentclass{KodeBook}
	\input{calls}
	\begin{document}
		\mainmatter
	
\fi
%=====================================================================
\changegraphpath{../img/sem-phrases/}
\chapter{Sémantique des phrases}

\begin{introduction}[LES LAN\textcolor{white}{G}UES]
	\lettrine{G}{énéralement}, une phrase se compose d'une action et des composants auteur d'elle qui jouent des rôles thématiques.
	Dans l'analyse syntaxique, nous avons vu que la phrase peut être décomposée en : sujet, verbe et objet.
	En français, la plupart du temps, le sujet est celui qui a fait l'action ; mais pas toujours. 
	Afin de représenter une phrase sémantiquement, nous devons trouver les rôles de chaque composant. 
	La représentation peut être logique, graphique, vectorielle, etc. 
	Nous pouvons avoir la représentation vectorielle d'une phrase en calculant le centre des embeddings des mots qui lui composent. 
	Les deux autres approches vont être présentées en détail dans ce chapitre.  
\end{introduction} 


Trouver les rôles sémantiques des composants d'une phrase est le premier pas vers sa représentation sémantique. 
Une bonne représentation est celle qui n'a aucune relation avec une langue précise. 
Une représentation sémantique d'une phrase a plusieurs applications : 
\begin{itemize}
	\item Compréhension du langage naturel
	\item Questions-Réponses
	\item Recherche d'information
	\item Traduction automatique
	\item Résumé automatique
\end{itemize}

%===================================================================================
\section{Rôles sémantiques}
%===================================================================================

Chaque groupe nominal joue un rôle sémantique dans un évènement de la phrase. 
Afin de comprendre une phrase ou représenter son sens, nous devons détecter ces rôles.
Prenons les phrases suivantes :
\begin{enumerate}
	\item \expword{Mon chat a attrapé une souris \underline{avec ses griffes}} 
	\item \expword{Mon chat a attrapé une souris \underline{avec sa queue}}
	\item \expword{Mon chat a attrapé une souris \underline{avec un autre chat}}
\end{enumerate}
Dans les trois phrases, ``Mon chat" est celui qui a fait l'évènement (agent) et ``une souris" c'est celui qui l'a subi (thème).
Malgré que les compléments d'objet indirects des trois phrases se commencent par la préposition ``avec", les trois syntagmes nominaux qui la suivent ont des rôles sémantiques différents. 
Le syntagme ``ses griffes" représente l'instrument, ``sa queue" représente la moyenne et ``un autre chat" représente un autre agent.
Ici, nous allons présenter quelques rôles sémantiques et deux ressources pour les représenter.

\subsection{Rôles thématiques}

Le rôle thématique (sémantique) décrit le  sens d'un groupe nominal par rapport un évènement exprimé par un verbe de la phrase. 
Le tableau \ref{tab:roles-them} représente quelques rôles thématiques avec leurs descriptions et exemples.
Contrairement aux relations de dépendance, ces rôles ne décrivent pas la structure de la phrase.
Par exemple, l'agent (celui qui a fait l'action) peut être un sujet (``\expword{\underline{Karim} présente le cours}") où un objet indirect (``\expword{Le cours est présenté par Karim}").
\begin{table}[ht]
	\centering\small
	\begin{tabular}{p{.14\textwidth}p{.35\textwidth}p{.43\textwidth}}
		\hline\hline
		\textbf{Rôle} & \textbf{Description} & \textbf{Exemple}\\
		\hline
		AGENT &
		Le causeur volontaire d'un évènement &
		\expword{\ul{John} a cassé la fenêtre avec une pierre.}\\
		
		EXPERIENCER & 
		L'expérimentateur d'un évènement & 
		\expword{\ul{John} a mal à la tête.}\\
		
		FORCE &
		Le causeur non volontaire d'un évènement &
		\expword{\ul{Le vent} souffle les débris.}\\
		
		THEME &
		Le participent affecté directement par l'évènement &
		\expword{John a cassé \ul{la fenêtre} avec une pierre.}\\
		
		RESULT &
		Le produit final d'un évènement &
		\expword{La ville a construit \ul{un terrain de baseball}.}\\
		
		CONTENT &
		Une proposition ou e contenu d'un évènement propositionnel &
		\expword{Mona a demandé	\ul{``Vous avez rencontré Mary Ann dans un supermarché?"}}\\
		
		INSTRUMENT &
		Un instrument utilisé dans l'évènement &
		\expword{\ul{une pierre} a cassé la fenêtre.}\\
		
		BENEFICIARY &
		Le bénéficiaire d'un évènement &
		\expword{Ann fait des réservations d'hôtel pour \ul{son patron}.}\\
		
		SOURCE &
		L'origine de l'objet d'un évènement de transfert &
		\expword{Je suis arrivé de \ul{Boston}.}\\
		
		GOAL &
		La destination de l'objet d'un évènement de transfert &
		\expword{Je suis allé à \ul{Portland}.}\\
		
		LOCATIVE & 
		La spécification du lieu où se situe l'action ou l'événement désigné par le prédicat &
		\expword{J'habite à \ul{Jijel}.}\\
		\hline\hline
	\end{tabular}
	\caption[Quelques rôles thématiques.]{Quelques rôles thématiques \cite{2019-jurafsky-martin}.}
	\label{tab:roles-them}
\end{table}

\subsection{FrameNet}

\keyword[F]{FrameNet}\footnote{FrameNet : \url{https://framenet.icsi.berkeley.edu/fndrupal/} [visité le 2021-09-11]} est un projet qui vise à annoter les rôles sémantiques en se basant sur la théorie ``\keyword{Frame semantics}" (Sémantique des cadres) de \keyword{Fillmore}. 
\keyword[N]{NLTK}\footnote{NLTK Framework : \url{https://www.nltk.org/howto/framenet.html} [visité 2021-09-11]} fournit un API pour utiliser \keyword[F]{FrameNet}. 
Un cadre est une représentation schématique d'une situation avec des participants ayants des rôles sémantiques.
Il doit pouvoir détecter la reformulation d'une phrase avec le même sens. 
Par exemple, les phrases suivantes ont le même cadre :
\begin{itemize}
	\item \expword{The price of petrol increased.}
	\item \expword{The price of petrol rose.}
	\item \expword{There has been a rise in the price of petrol.}
\end{itemize}


\keyword[F]{FrameNet} se compose d'un ensemble des cadres sémantiques préparés manuellement. 
Un cadre (Frame) est une représentation schématique d'une situation.
Chaque cadre se compose d'un nom, une définition, des éléments de cadre, des  relations avec d'autres cadres et des unités lexicales. 
Un élément d'un cadre (Frame Element : FE) est un rôle sémantique spécifique au cadre qui décrit un participant ou une situation dans le cadre. 
Il est composé d'un rôle sémantique, un type sémantique, une définition et un exemple. 
Il existe deux types de rôles : de base (Core) qui sont essentiels, et d'autres secondaires (Non-Core).
Les relations avec les autres cadres sont représentées comme un tuple (type-relation, cadre). 
Parmi ces relations, nous pouvons mentionner : l'héritage, l'utilisation, la causalité, etc. 
Les unités lexicales (Lexical Units) sont représentées par un ensemble des lemmes avec leurs catégories grammaticales.
Une unité lexicale déclenche le cadre lorsqu'elle est rencontrée.

Le tableau \ref{tab:framenet-cadre-partie-exp} représente le cadre sémantique appelé ``Cause\_to\_fragment" (faire fragmenter). 
Les éléments essentiels d'un cadre sont : l'agent qui est un être sensible, une cause, un patient complet et des pièces. 
La définition décrit comment ces éléments interagissent.
Il existe des éléments secondaires comme le degrés de fracture, l'instrument utilisé dans la fragmentation. 
Concernant les relations avec les autres cadres, nous pouvons citer ``Is Causative of : Breaking\_apart". 
Donc, le fait de fragmenter une chose est la cause de se briser. 
Ce cadre peut être activé par plusieurs mots comme les verbes : break apart, dissect, smash, etc.

\begin{table}[!htbp]
	\centering\footnotesize
	\begin{tabular}{p{.23\textwidth}p{.7\textwidth}}
		\hline\hline
		\multicolumn{2}{c}{\textbf{Cause\_to\_fragment}} \\
		\hline
		Définition & An \textcolor{red}{Agent} suddenly and often violently separates the \textcolor{red}{Whole\_patient} into two or more smaller \textcolor{red}{Pieces}, resulting in the \textcolor{red}{Whole\_patient} no longer existing as such. Several lexical items are marked with the semantic type Negative, which indicates that the fragmentation is necessarily judged as injurious to the original \textcolor{red}{Whole\_patient}. Compare this frame with Damaging, Render\_non-functional, and Removing. \\	
		
		\hline\hline
		\multicolumn{2}{c}{\textbf{FEs (Core)}} \\
		\hline
		Agent [Agt] \newline \textcolor{blue}{\scriptsize Semantic Type: Sentient} & 
		The conscious entity, generally a person, that performs the intentional action that results in the \textcolor{red}{Whole\_patient} being broken into \textcolor{red}{Pieces}. \newline \expword{\underline{I and I alone} can SHATTER the gem and break the curse.} \\
		
		Cause [cau] & 
		An event which leads to the fragmentation of the \textcolor{red}{Whole\_patient}. \\
		
		Pieces [Pieces]	& 
		The fragments of the \textcolor{red}{Whole\_patient} that result from the \textcolor{red}{Agent}'s action.
		\newline
		\expword{I SMASHED the toy boat to \underline{flinders}.} \\
		
		Whole\_patient [Pat] & The entity which is destroyed by the \textcolor{red}{Agent} and that ends up broken into \textcolor{red}{Pieces}.
		\newline
		\expword{Shattering someone's confidence is a little different than SHATTERING \underline{a dish}.} \\
		
		\hline\hline
		\multicolumn{2}{c}{\textbf{FEs (None-Core)}} \\
		\hline
		Degree [Degr] \newline \textcolor{blue}{\scriptsize Semantic Type: Degree} &
		The degree to which the fracturing is completed. 
		\newline
		\expword{I SHATTERED the vase \underline{completely}.} \\
		
%		Explanation [Exp] \newline \textcolor{blue}{Semantic Type: State\_of\_affairs} &
%		A state of affairs that the Agent is responding to in performing the action. \newline
%		\expword{He TORE the treaty UP out of frustration.} \\
		
		
		Explanation [Exp] \newline \textcolor{blue}{\scriptsize Semantic Type: State\_of\_affairs} &	
		A state of affairs that the \textcolor{red}{Agent} is responding to in performing the action.
		\newline
		\expword{He TORE the treaty UP \underline{out of frustration}.} \\
		
		Instrument [Ins] \newline \textcolor{blue}{\scriptsize Semantic Type: Physical\_entity} &
		An entity directed by the  \textcolor{red}{Agent} that interacts with a \textcolor{red}{Whole\_patient} to accomplish its fracture. \\
		
		
		\multicolumn{2}{c}{\large ...} \\
		
		\hline\hline
		\multicolumn{2}{c}{\textbf{Frame-frame Relations}} \\
		\hline
		Inherits from & Transitive\_action \\
		Uses & Destroying \\
		Is Causative of & Breaking\_apart \\
		
		\hline\hline
		\multicolumn{2}{c}{\textbf{Lexical Units}} \\
		\hline
		& break apart.v, break down.v, break up.v, break.v, chip.v, cleave.v, dissect.v, dissolve.v, fracture.v, fragment.v, rend.v, rip up.v, rip.v, rive.v, shatter.v, shiver.v, shred.v, sliver.v, smash.v, snap.v, splinter.v, split.v, take apart.v, tear up.v, tear.v \\
		\hline\hline
	\end{tabular}
	\caption[Exemple d'une partie d'un cadre sémantique de FrameNet.]{Exemple d'une partie du cadre sémantique ``Cause\_to\_fragment", \url{ https://framenet2.icsi.berkeley.edu/fnReports/data/frameIndex.xml?frame=Cause_to_fragment} [visité le 2021-09-11].
	}
	\label{tab:framenet-cadre-partie-exp}
\end{table}


Les unités lexicales sont utilisées pour déclencher des cadres. 
Une unité lexicale est un tuple (lemme, catégorie lexicale) qui représente un sens d'un mot donné.
Le sens est lié à un cadre sémantique.
Le tableau \ref{tab:framenet-cadres-exp} représente quelques unités lexicales du mot ``break".
Parmi les cadres activés par ce mot, nous trouvons le cadre ``Cause\_to\_fragment" présenté dans le tableau \ref{tab:framenet-cadre-partie-exp}. 
En général, les verbes sont les déclencheurs les plus utilisés dans \keyword[F]{FrameNet}.

\begin{table}[!ht]
	\centering
	\begin{tabular}{p{.15\textwidth}p{.25\textwidth}p{.5\textwidth}}
		\hline\hline
		\textbf{Lexical Unit} & \textbf{Frame} & \textbf{Exemple}\\
		\hline
		break.n & Opportunity & \\	
		break.v & Cause\_harm & \expword{Jolosa broke a rival player's jaw.}\\
		break.v & Compliance & \expword{He broke his promess.}\\
		break.v & Experience\_bodily\_harm & \expword{I broke my arm in the accident.}\\
		break.v & Cause\_to\_fragment & \expword{Michael broke the bottle against his head}\\
		break.v & Render\_nonfunctional & \expword{I guess I broke the doorknob by twisting it too hard.}\\
		break.v & Breaking\_off & \expword{The handle broke off of the pot.}\\
		break.v & Breaking\_apart & \expword{The handle broke off of the pot.}\\
		\hline\hline
	\end{tabular}
	\caption{Quelques unités lexicales du mot ``break".}
	\label{tab:framenet-cadres-exp}
\end{table}

\keyword[F]{FrameNet} fournit un ensemble des entrées lexicales (Lexical Entry).
Une entrée lexicale représente la structure syntaxique d'un cadre par rapport une unité lexicale. 
Elle contient un tableau qui lie chaque élément de cadre avec l'ensemble de ces réalisations syntaxiques. 
Par exemple, l'élément ``Whole\_patient" est lié avec ``NP.Obj" (un syntagme nominal qui est un objet) dans 29 exemples.
\keyword[F]{FrameNet} fournit un autre tableau qui représente la liste de patrons de valence. 
Chaque ligne représente l'ordre des éléments de cadre par rapport à la structure syntaxique.
Un exemple de la liste de patrons de valence du verbe ``fracture" du cadre ``Cause\_to\_fragment" est donné dans le tableau \ref{tab:framenet-entree-exp}. 
Chaque patron est accompagné par le nombre des exemples annotés.
 
\begin{table}[ht]
	\centering\small
	\begin{tabular}{|p{.12\textwidth}|p{.12\textwidth}|p{.12\textwidth}|p{.12\textwidth}|p{.12\textwidth}|p{.12\textwidth}|}
		\hline
		\textbf{Number Annotated} & \multicolumn{5}{|l|}{\textbf{Patterns}}\\
		\hline
		\multicolumn{6}{l}{ }\\
		
		\hline
		1 TOTAL & \textcolor{red}{Agent} & \textcolor{red}{Instrument} & \textcolor{red}{Pieces} & \textcolor{red}{Whole\_patient} & \\
		\hline
		(1) & CNI \newline - - & PP[with] \newline Dep & INI \newline - - & NP \newline Ext & \\
		\hline
		\multicolumn{6}{l}{ }\\
		
		\hline
		1 TOTAL & \textcolor{red}{Agent} & \textcolor{red}{Means} & \textcolor{red}{Pieces} & \textcolor{red}{Time} & \textcolor{red}{Whole\_patient} \\
		\hline
		(1) & NP \newline Ext & 2nd \newline - - & INI \newline - - & Sinterrog \newline Dep & NP \newline Obj \\
		\hline
		\multicolumn{6}{l}{ }\\
		
		\hline
		4 TOTAL & \textcolor{red}{Agent} & \textcolor{red}{Pieces} & \textcolor{red}{Whole\_patient} & & \\
		\hline
		(4) & NP \newline Ext & INI \newline - - & NP \newline Obj & & \\
		\hline
	\end{tabular}
	\caption[Extrait de liste de patrons de valence de FrameNet.]{Entrée lexicale du déclencheur ``fracture" (verbe) du cadre ``Cause\_to\_fragment" : extrait de liste de patrons de valence.}
	\label{tab:framenet-entree-exp}
\end{table}

\keyword[F]{FrameNet} fournit un ensemble de phrases annotées pour chaque entrée lexicale. 
La figure \ref{fig:framenet-lex} représente un extrait des annotations lexicographiques du verbe ``fracture" et le cadre ``Cause\_to\_fragment". 
Ici, les éléments de cadres absents dans l'annotation sont marqués par ``[INI]" (indefinite null instantiation).
Le corpus annoté est généralement utilisé pour entraîner ou tester un système d'étiquetage des rôles sémantiques.

\begin{figure}[ht]
	\centering 
\begin{tcolorbox}[colback=white, colframe=blue, boxrule=1pt, text width=.8\textwidth]
	\footnotesize
	\begin{itemize}
		\item 429-s20-rcoll-skull
		\begin{enumerate}\footnotesize
			\item \ [\textsubscript{\color{red}Agent} Former England Under-21 player Keith Benton] FRACTURED\textsuperscript{\color{red}Target} [\textsubscript{\color{red}Whole\_patient} his son Seb 's skull] [\textsubscript{\color{red}Time} when he hit the ball into the crowd during a match in Buckingham]. [\textsubscript{\color{red}Pieces} INI] 
			\item \ [\textsubscript{\color{red}Agent} He] hit a lamp-post and FRACTURED\textsuperscript{\color{red}Target} [\textsubscript{\color{red}Whole\_patient} Mike 's skull]. [\textsubscript{\color{red}Pieces} INI] 
			\item When he found the man [\textsubscript{\color{red}Agent} he] threw the acid into his face and beat him with the hammer , FRACTURING\textsuperscript{\color{red}Target} [\textsubscript{\color{red}Whole\_patient} his skull] and his thumb. [\textsubscript{\color{red}Pieces} INI] 
			\item \ [\textsubscript{\color{red}Agent} A nanny] has been jailed after FRACTURING\textsuperscript{\color{red}Target} [\textsubscript{\color{red}Whole\_patient} the skulls of two new born babies in her care]. [\textsubscript{\color{red}Pieces} INI] 
		\end{enumerate}
		\item 520-s20-np-vping
		\item 620-s20-np-ppother
		\item 660-s20-trans-simple
		\begin{enumerate}\footnotesize
			\item \ [\textsubscript{\color{red}Agent} Then 17-year-old Lee Diaz, of North End Gardens, Bishop Auckland], attacked a second party-goer, Carl Gent, punching him in the face and FRACTURING\textsuperscript{\color{red}Target} [\textsubscript{\color{red}Whole\_patient} his jaw]. [\textsubscript{\color{red}Pieces} INI] 
		\end{enumerate}
		
		\item 680-s20-pass
		\begin{enumerate}\footnotesize
			\item \ [\textsubscript{\color{red}Whole\_patient} It] was FRACTURED\textsuperscript{\color{red}Target} [\textsubscript{\color{red}Instrument} with a solvent-cleaned chisel], and the outer orange layer discarded. [\textsubscript{\color{red}Agent} CNI][\textsubscript{\color{red}Pieces} INI] 
		\end{enumerate}
	\end{itemize}\vspace*{-1cm}
\end{tcolorbox}
	
	\caption[Extrait des annotations lexicographiques dans FrameNet.]{Extrait des annotations lexicographiques du déclencheur ``fracture" (verbe) du cadre ``Cause\_to\_fragment".}
	\label{fig:framenet-lex}
\end{figure}

\subsection{PropBank}

\keyword[P]{PropBank}\footnote{PropBank : \url{https://propbank.github.io/} [visité le 2021-09-11]} (Propositional Bank) est un corpus des phrases annotées en se basant sur la structure Prédicat-Arguments. 
\keyword[N]{NLTK}\footnote{NLTK PropBank : \url{https://www.nltk.org/howto/propbank.html} [visité le 2021-09-11]} fournit un API pour accéder à \keyword[P]{PropBank}. 
L'annotation se base sur moins de rôles sémantiques : agent et patient. 
L'agent participe volontairement dans un évènement ou un état.
Il peut aussi causer un évènement ou un changement d'état d'un autre participant. 
Le patient est le participant qui éprouve un changement d'état.
Il peut aussi être affectée par un autre participant.


\keyword[P]{PropBank} est structuré comme un ensemble des fichiers de prédicats (verbes) ; en général sous formes de fichiers XML. 
Chaque prédicat définit plusieurs ensembles de rôles (rolesets) qui représentent les différents sens.
La figure \ref{fig:propbank-predicat} représente un extrait du premier sens du prédicat ``know" dans \keyword[P]{PropBank}.
Chaque roleset est structuré comme suit : 
\begin{itemize}
	\item Un identifiant numérique et un ensemble des verbes ayant le même sens.
	Par exemple, \expword{know.01 : be cognizant of, realize ; know.02 : be familiar with, have experienced}.
	
	\item Des rôles : un verbe dans un roleset a plusieurs arguments annotés par le mot clé \keyword{Arg} suivi par un numéro entre $0$ et $5$. 
	Arg0 et Arg1 sont toujours réservés pour le PROTO-AGENT et le PROTO-PATIENT respectivement. 
	Le reste des arguments ne sont pas consistants dans le corpus. 
	En général, Arg2 veut dire : benefactive, instrument, attribute, ou end state ; Arg3 veut dire : start point, benefactive, instrument, ou attribute ; et Arg4 veut dire : end point.
	Des modificateurs (Modifiers) peuvent être fournis par un roleset ; ils sont marqués par le mot clé \keyword{ArgM}. 
	Par exemple, ArgM-TMP : Quand ? ArgM-LOC : Où ? ArgM-MNR : Comment ?
	\item Des exemples annotés
\end{itemize} 


\begin{figure}[ht]
	\centering
\begin{tcolorbox}[colback=white, colframe=blue, boxrule=1pt, text width=.85\textwidth]
	\footnotesize
	\begin{itemize}
		\item \textbf{Roleset id}
		\begin{itemize}\scriptsize
			\item \textbf{know.01} : be cognizant of, realize
		\end{itemize}
		\item \textbf{Roles}
		\begin{itemize}\scriptsize
			\item \textbf{Arg0} : knower
			\item \textbf{Arg1} : fact that is known
			\item \textbf{Arg2} : entity that arg1 is known ABOUT
		\end{itemize}
		
		\item \textbf{Example: know-v: sentential thing known}
		\begin{itemize}\scriptsize
			\item \ [\textsubscript{\color{red}Arg0} The other side] knows [\textsubscript{\color{red}Arg1} that Giuliani has always been prochoice].
		\end{itemize}
		
		\item \textbf{Example: know-v: attributive}
		\begin{itemize}\scriptsize
			\item \ [\textsubscript{\color{red}Arg0} He] did[\textsubscript{\color{red}ArgM-NEG} n't] know [\textsubscript{\color{red}Arg1} (anything)] [\textsubscript{\color{red}Arg2} about most of the cases] [\textsubscript{\color{red}ArgM-TMP} until Wednesday].
		\end{itemize}
	\end{itemize}\vspace*{-1cm}
\end{tcolorbox}
	\caption[Extrait des annotations ProBank d'un prédicat.]{Extrait des annotations ProBank du prédicat ``know", \url{http://verbs.colorado.edu/propbank/framesets-english-aliases/know.html} [visité le 2021-09-11].}
	\label{fig:propbank-predicat}
\end{figure}

%===================================================================================
\section{Étiquetage de rôles sémantiques}
%===================================================================================

L'étiquetage de rôles sémantiques, en anglais \ac{srl}, est la tâche d'attribution des rôles sémantiques aux mots ou aux expressions dans une phrase.
La figure \ref{fig:srl-exp} représente une phrase avec l'étiquetage des rôles sémantiques basé sur \keyword[P]{PropBank}.
C'est une tâche d'étiquetage des séquences. 
Elle peut être implémentée soit en utilisant des caractéristiques ou en utilisant les réseaux de neurones.

\begin{figure}[ht]
	\centering
	\hgraphpage[.8\textwidth]{exp-srl2_.pdf}
	\caption[Exemple d'étiquetage de rôles sémantiques en se basant sur PropBank.]{Exemple d'étiquetage de rôles sémantiques en se basant sur PropBank, \url{https://demo.allennlp.org/semantic-role-labeling/} [visité le 2022-05-02].}
	\label{fig:srl-exp}
\end{figure}

\subsection{En utilisant des caractéristiques}

Nous commençons par analyser la phrase syntaxiquement pour avoir son arbre syntaxique. 
Ensuite, nous parcourons chaque nœud de ce dernier pour décider la classe en se basant sur certaines caractéristiques. 
Les classes peuvent être celles de \keyword[F]{FrameNet} ou \keyword[P]{PropBank} en plus de ``None" pour marquer un nœud sans rôle.
Un classificateur est entraîné afin de classer un nœud en utilisant des caractéristiques comme :
\begin{itemize}
	\item Le prédicat principal de la phrase. En général, c'est le verbe du \keyword[S]{syntagme} verbal (VP : verbal phrase) descendant directe de la racine.
	\item Le type du \keyword[S]{syntagme} (Ex. \expword{NP, S, PP}).
	\item Le mot d'entête (principal) du \keyword[S]{syntagme}. 
	Le mot principal d'un \keyword[S]{syntagme} nominal est un nom, celui d'un \keyword[S]{syntagme} prépositionnel est une préposition, etc. 
	Celui-ci peut être détecté en se basant sur la grammaire du langage.
	\item La catégorie grammaticale du mot principal.
	\item Le chemin du nœud concerné vers le prédicat. 
	La figure \ref{fig:srl-arbre-chemin} représente un arbre syntaxique avec le chemin d'un syntagme vers le prédicat principal.
	Dans cet exemple, le syntagme ``NP" est loin de la racine qui est loin du prédicat (verbe) de 2 arcs.
	Dans ce cas, le chemin sera \expword{NP\textuparrow S\textdownarrow VP \textdownarrow VPD} (de NP aller en haut vers S ; aller en bas vers VP ; et enfin, aller en bas vers VPD).
	\item La voie : active ou passive.
	\item La position par rapport au prédicat : avant ou après.
	\item ...
\end{itemize}

\begin{figure}[ht]
	\centering
	\hgraphpage[.7\textwidth]{srl-arbre.pdf}
	\caption[Exemple d'un arbre syntaxique avec le chemin vers le prédicat principal.]{Exemple d'un arbre syntaxique avec le chemin d'un syntagme vers le prédicat principal ; figure reconstruite de \cite{2019-jurafsky-martin}.}
	\label{fig:srl-arbre-chemin}
\end{figure}

Quelques optimisations peuvent être appliquées afin d'améliorer la tâche d'annotation.
Les feuilles de l'arbre représentent les catégories grammaticales. 
Donc, nous ne les classons pas puisque seuls les syntagmes peuvent être des arguments. 
Nous pouvons, aussi, entraîner un classificateur pour classer le nœud comme ``Argument" ou ``None".
Ensuite, entraîner un autre classificateur seulement avec les nœuds avec ``Argument".


\subsection{En utilisant les réseaux de neurones}

Nous avons vu que l'étiquetage des séquences peut être implémenté en utilisant la méthode \keyword[I]{IOB}  (inside, outside, begins). 
La figure \ref{fig:srl-embedding} représente un système d'étiquetage de rôles sémantiques en utilisant les \keywordpl[L]{LSTM} proposé par \citet{2017-he-al}. 
Dans un moment donné, l'entrée est le \keyword[E]{embedding} du mot courant fusionné avec un indicateur de prédicat (prédicat ou non). 
Chaque couche $l$ est une cellule \keyword[L]{LSTM} qui peut être en avant ($l$ est impaire) ou en arrière.
Pour contrôler la quantité de l'information qui vient de la couche précédente ($h'_{l-1, t}$), les auteurs utilisent une porte de transformation similaire à celle d'initialisation des cellules \keyword[G]{GRU}.
Cette cellule apprend une pondération $r_{l, t}$ qui décide combien d'information nous devons passer de la couche actuelle $h'_{l, t}$ et de la couche précédente $h'_{l-1, t}$.
La sortie est un vecteur des probabilités des classes \keyword[P]{PropBank} encodées en utilisant la méthode \keyword[I]{IOB}.

\begin{figure}[ht]
	\centering
	\hgraphpage[.7\textwidth]{srl-lstm.pdf}
	\caption[Système d'étiquetage de rôles sémantiques avec LSTM.]{Système d'étiquetage de rôles sémantiques avec LSTM \cite{2017-he-al} ; figure adaptée.}
	\label{fig:srl-embedding}
\end{figure}

%===================================================================================
\section{Représentation sémantique des phrases}
%===================================================================================

Une représentation sémantique d'une phrase ne doit pas être dépendante de la structure syntaxique. 
Elle doit pouvoir exprimer les phrases ayant le même sens de la même manière. 
Par exemple, les deux phrases suivantes doivent avoir la même représentation :
\begin{itemize}
	\item \expword{L'étudiant a préparé un rapport.}
	\item \expword{Un rapport a été préparé par l'étudiant.}
\end{itemize}

Nous avons vu qu'une phrase peut être représentée par un ensemble de cadres en utilisant \keyword[F]{FrameNet}. 
En plus de cette représentation, nous pouvons représenter le sens en utilisant la logique du premier ordre ou en utilisant les graphes. 
Parmi les difficultés rencontrées dans la tâche d'analyse sémantique, nous pouvons citer l'ambigüité.
Par exemple, la phrase ``\expword{Elle a emporté les clefs de la maison au garage.}" veut dire que la maison est une source de l'action ``emporter" ou un dépendant des clefs. 

\subsection{Logique du premier ordre}

La logique du premier ordre, \ac{fol}, peut être utilisée pour représenter le sens des phrases.
C'est une représentation indépendante de la structure syntaxique du langage.
Une expression en \ac{fol} peut être vérifiée et inférée facilement.
Elle se compose des termes, des prédicats, des connecteurs et des qualificateurs. 

Un terme représente un objet qui peut être : une constante, une fonction ou une variable. 
Une \optword{constante} représente un objet spécifique dans le modèle.
Par exemple, les mots \expword{Karim, ESI, Algérie} qui sont des entités nommées  : nom propre, organisation et pays respectivement.
Bien sûr, une constante peut référer un nom abstrait comme par exemple ``\expword{Informatique}".
Des fois, nous référons un objet, pas par son nom mais, par sa relation avec une constante. 
Par exemple, l'expression ``\expword{emplacement de l'ESI}" réfère à une place. 
Mais en utilisant seulement les constantes, nous ne pouvons pas la décrire en utilisant \ac{fol}. 
Une \optword{fonction} peut être utilisée afin de retourner un objet en fonction d'un autre. 
Dans ce cas, l'expression précédente peut être représentée comme ``\expword{EmplacementDe(ESI)}". 
Prenons maintenant l'expression ``\expword{un étudiant}" qui réfère un objet non spécifique ; nous ne savons pas qui est cet étudiant. 
Les deux types de termes (constante et fonction) ne peuvent pas représenter cette information. 
Une \optword{variable} peut être utilisée comme référence vers un objet inconnu (anonyme). 
Chaque variable est représentée comme une lettre en minuscule (Ex. \expword{x, y, z}).

Un prédicat représente une relation logique entre plusieurs termes qui retourne soit vrai ou faux.
Prenons l'exemple ``\expword{ESI enseigne l'informatique}".
Cette phrase peut être représentée comme : 
\[enseigner(ESI, INFORMATIQUE)\]
Dans cet exemple, le prédicat est un verbe transitif. 
Maintenant, prenons l'exemple ``\expword{ESI est une école}".
Cette phrase peut être représentée en utilisant un prédicat unitaire :
\[ecole(ESI)\]
Ici, le prédicat n'est pas utilisé pour décrire une relation entre plusieurs termes. 
Il est utilisé pour représenter une propriété de la constante ``\expword{ESI}". 
Nous devons être capable de différencier entre un prédicat unitaire et une fonction. 
Un prédicat retourne une valeur logique, or une fonction retourne un nouvel objet.
Prenons un exemple avec les deux : ``Karim connaît l'adresse de l'ESI". 
Cette phrase peut être représentée comme : 
\[connaitre(KARIM, AdresseDe(ESI))\]

Les prédicats, étant des relations logiques, doivent être liés pour avoir une expression plus complexe. 
Par exemple, la phrase ``\expword{Karim est un enseignant à l'ESI qui est une école.}" peut être représentée comme :
\[enseignant(KARIM) \wedge location(ESI) \wedge ecole(ESI)\]
Ici, nous avons utilisé un prédicat $location$ pour représenter l'emplacement. 
Aussi, nous avons employé le connecteur $\wedge$ afin de lier les prédicats. 
La liste des connecteurs possibles est la suivante : ET ($ \wedge $) OU ($ \vee $), NON ($ \neg $ ), IMPLIQUE ($\rightarrow$) et EQUIVALENT ($ \Leftrightarrow $).

Les variables sont utilisées afin de référer des objets anonymes.  
Mais, il n'ont pas la capacité à décrire qu'il s'agit d'un objet ou tous les objets d'une collection. 
Cela est possible en utilisant les quantificateurs : IL-EXISTE ($\exists$) et POUR-TOUS ($\forall$).
Prenons l'exemple ``\expword{Je mange à un restaurant près de l'ESI.}".
Ceci peut être représenté comme suit : 
\[\exists x\ Restaurant(x) \wedge PresDe(EmplacementDe(x), EmplacementDe(ESI)) \wedge  MangerA(Interlocuteur, x)\]

Dans ce dernier exemple, nous avons utilisé le prédicat ``$MangerA$" pour indiquer la location où on a mangé. 
Si nous voulions décrire la location, le temps, etc. pour chaque évènement, nous devrions enrichir notre domaine avec des prédicats verbe-location, verbe-temps, etc. 
Cela va causer le domaine à exploser ; un nombre énorme des prédicats. 
Aussi, nous ne pouvons pas utiliser un nombre variable des arguments pour chaque prédicat puisque dans \ac{fol} chaque prédicat a un nombre précis des arguments. 
Une solution est d'introduire une variable d'évènement et nous utilisons des prédicats pour indiquer la location de l'évènement ($Location$), temps de l'évènement ($Temps$), etc.
Le prédicat de l'évènement sera utilisé avec un prédicat pour l'agent et un autre pour le patient.
L'exemple précédent sera représenté comme suit : 
\[\exists x\ \exists e\ Restaurant(x) \wedge PresDe(EmplacementDe(x), EmplacementDe(ESI))\]
\[\wedge Manger(e) \wedge  Mangeur(e, Interlocuteur) \wedge Location(e, x)\]
Ici, l'évènement ``$e$" a été représenté comme une variable. 
Afin de définir le type de l'évènement, nous avons utilisé un prédicat unitaire ``$Manger(e)$". 
Afin de représenter les arguments de cet évènement, nous avons utilisé des prédicats binaires qui sont des rôles.
Le premier argument est la variable d'évènement et le deuxième est le participant ayant ce rôle.
Cette représentation est appelée une représentation des évènements néo-Davidsonienne d'après le philosophe Donald Davidson \cite{1967-davidson}.

%Formalisme
%\begin{figure}
%	\hgraphpage[0.6\textwidth]{LPO-gram_.pdf}
%	\caption{La grammaire spécifiant le syntaxe du logique du premier ordre d'après \cite{2019-jurafsky-martin} (Adaptée de \cite{2002-russell-norvig})}
%\end{figure}


\subsection{Graphes (AMR)}

\ac{amr} est un langage de représentation sémantique \cite{2013-banarescu-al} qui peut être représenté sous forme d'un graphe. 
Le graphe doit être raciné, étiqueté, dirigé et acyclique. 
Il sert à représenter une phrase indépendamment de la syntaxe.
Toutefois, il reste dépendant de l'anglais et ne peut pas être considéré comme un langage multilingue.
Un exemple de la représentation de la phrase ``The boy wants to go" est présenté dans la figure \ref{fig:amr-exp}.
La représentation \ac{amr} est illustrée sous deux formats : textuelle et graphique, en plus de la représentation logique.

\begin{figure}[ht]
	\centering
	\begin{minipage}{.3\textwidth}
		\optword{Format logique}
		
		\footnotesize
		$ \exists $ w, b, g : 
		
		instance(w, want-01) 
		
		$ \wedge $ instance(g, go-01) 
		
		$ \wedge $ instance(b, boy) 
		
		$ \wedge $ arg0(w, b) 
		
		$ \wedge $ arg1(w, g) 
		
		$ \wedge $ arg0(g, b)
	\end{minipage}
	\begin{minipage}{.35\textwidth}
		\optword{Format AMR}
		
		\begin{verbatim}
		(w / want-01
		:arg0 (b / boy)
		:arg1 (g / go-01
		:arg0 b))
		\end{verbatim}
		
	\end{minipage}
	\begin{minipage}{.3\textwidth}
		\optword{Format Graphe}
		
		\hgraphpage{amr-graphe-exp.pdf}
	\end{minipage}
	\caption[Exemple d'une représentation AMR.]{Exemple de la représentation AMR de la phrase : ``The boy wants to go".}
	\label{fig:amr-exp}
\end{figure}

Dans \ac{amr}, les concepts d'une phrase sont représentés sous forme de mots de l'anglais (Ex. \expword{boy}), des concepts de \keyword[P]{PropBank} (Ex. \expword{want-01}) ou des mots clés spéciaux. 
Le langage suit le modèle néo-Davidsonien ; chaque entité, évènement, propriété et état sont représenté comme une variable. 
Par exemple, la représentation ``\expword{(b / boy)}  veut dire ``b" est une instance du concept ``boy".
Les entités sont reliées par des relations.
Par exemple, la représentation ``\expword{(d / die-01 :location (p / park))}" veut dire qu'il y avait un mort ``d" dans le parc ``p".
\ac{amr} utilise les arguments des cadres \keyword[P]{PropBank} en plus d'autres relations présentées dans le tableau \ref{tab:amr-rel}.

\begin{table}[ht]
	\centering
	\begin{tabular}{>{\raggedright}p{.25\textwidth}>{\raggedright\arraybackslash}p{.7\textwidth}}
		\hline\hline
		Arguments du cadre  & 
		:arg0, :arg1, :arg2, :arg3, :arg4, :arg5 \\
		\hline
		Relations sémantiques générales &
		:accompanier, :age, :beneficiary, :cause, :compared-to, :concession, 
		
		:condition, :consist-of, :degree, :destination, :direction, :domain, 
		
		:duration, :employed-by, :example, :extent, :frequency, :instrument, 
		
		:li, :location, :manner, :medium, :mod, :mode, :name, :part, :path, 
		
		:polarity, :poss, :purpose, :source, :subevent, :subset, :time, :topic, :value \\
		\hline
		Relations de quantité &
		:quant, :unit, :scale \\
		\hline
		Relations de date &
		:day, :month,
		:year, :weekday, :time, :timezone, :quarter, :dayperiod, 
		
		:season, :year2, :decade, :century, :calendar, :era \\
		\hline
		Relations de liste & 
		:op1, :op2, :op3, :op4, :op5,
		:op6, :op7, :op8, :op9, :op10\\
		\hline\hline
	\end{tabular}
	\caption{Relations AMR.}
	\label{tab:amr-rel}
\end{table}


%\begin{itemize}
%	\item \optword{Arguments du cadre (frame)} : Selon PropBank
%	\begin{itemize}
%		\item :arg0, :arg1, :arg2, :arg3, :arg4, :arg5
%	\end{itemize}
%	\item \optword{Relations sémantiques générales}
%	\begin{itemize}
%		\item :accompanier, :age, :beneficiary, :cause, :compared-to, :concession, :condition, :consist-of, :degree, :destination, :direction, :domain, :duration, :employed-by, :example, :extent, :frequency, :instrument, :li, :location, :manner, :medium, :mod, :mode, :name, :part, :path, :polarity, :poss, :purpose, :source, :subevent, :subset, :time, :topic, :value
%	\end{itemize}
%	\item \optword{Relations de quantité}
%	\begin{itemize}
%		\item :quant, :unit, :scale
%	\end{itemize}
%	\item \optword{Relations de date}
%	\begin{itemize}
%		\item :day, :month,
%		:year, :weekday, :time, :timezone, :quarter,
%		:dayperiod, :season, :year2, :decade, :century,
%		:calendar, :era
%	\end{itemize}
%	\item \optword{Relations de liste}
%	\begin{itemize}
%		\item :op1, :op2, :op3, :op4, :op5,
%		:op6, :op7, :op8, :op9, :op10
%	\end{itemize}
%\end{itemize}


\section{Analyse sémantique}

Dans l'analyse sémantique, nous allons présenter comment passer d'une phrase en langage naturel vers une représentation de la logique du premier ordre. 
Cette analyse est appliquée au fur et à mesure avec l'analyse syntaxique en utilisant des règles sémantiques. 
Ces dernières peuvent être des $\lambda $-expressions qui décrivent des fonctions anonymes sur des variables. 
Une $\lambda $-expression est écrite sous forme ``$ \lambda x.P(x)$" ; elle représente une fonction. 
Ces fonctions peuvent être appliquées par une opération appelée $\lambda $-Reduction qui sert à substituer une variable par une expression. 
Il y a deux annotations $ \lambda x.P(x)(A)$ ou $ \lambda x.P(x)@A$ pour dire : substituer la première variable par ``A" (dans ce qui suit, nous allons utiliser la première). 
Prenons une fonction avec deux variables qui représente le fait que la variable $x$ utilise $y$ : 
\[\lambda y.\lambda x.UTILISER(x, y)\]
Le remplacement commence toujours par le premier $\lambda$ :
\[\lambda y.\lambda x.UTILISER(x, y)\ BERT = \lambda x.UTILISER(x, y)[y := BERT] = \lambda x.UTILISER(x, BERT)\] 
Après la réduction, le résultat reste toujours une $\lambda $-expression. 
Donc, nous pouvons appliquer une deuxième $\lambda $-Reduction :
\[\lambda x.UTILISER(x, BERT)\ KARIM = UTILISER(KARIM, BERT)\]

Maintenant, nous revenons à l'analyse sémantique. 
Étant donné la grammaire $G <\Sigma, N, P, S>$, nous affectons pour chaque variable de $N$ une réalisation sémantique (Ex. \expword{NP.sem}). 
Pour chaque production de $P$, nous affectons une opération sémantique : une expression en \ac{fol}, une $\lambda $-expression ou une $\lambda $-Reduction.
La réalisation sémantique  de la variable à gauche de la production sera l'exécution de l'opération sémantique.
Prenons l'exemple des règles syntaxiques annotées sémantiquement présentées dans le tableau \ref{tab:regles-sem1}.

\begin{table}[ht]
	\centering
	\begin{tabular}{llll}
		\hline\hline
		S  & \textrightarrow\ NP VP && VP.sem(NP.sem) \\
		VP & \textrightarrow\ V\textsubscript{t} NP && V\textsubscript{t}.sem(NP.sem)\\
		VP & \textrightarrow\ V\textsubscript{i} && V\textsubscript{i}.sem \\
		V\textsubscript{t}  & \textrightarrow\ utilise && $ \lambda $y.$ \lambda $x.UTILISER(x, y) \\
		V\textsubscript{i}  & \textrightarrow\ dort && $ \lambda $x.DORMIR(x) \\
		NP  & \textrightarrow\  Karim && KARIM \\
		NP  & \textrightarrow\  BERT && BERT \\
		\hline\hline
	\end{tabular}
	\caption{Grammaire à contexte libre minimale avec les annotations sémantiques.}
	\label{tab:regles-sem1}
\end{table}

Lors de l'analyse syntaxique, nous calculons la valeur sémantique de chaque variable visitée dans l'arbre syntaxique.
Dans notre cas, nous allons utiliser une analyse ascendante ; parcours postfixe de l'arbre syntaxique.
La figure \ref{fig:arbre-sem1} est un exemple d'une arbre syntaxique/sémantique de la phrase ``\expword{Karim utilise BERT}".
Nous commençons par appliquer la règle ``NP \textrightarrow\ Karim" pour avoir la réalisation sémantique : 
\[NP.sem = KARIM\]
Ensuite, nous appliquons la règle ``V\textsubscript{t} \textrightarrow\ utilise" pour avoir :
\[V_t.sem = \lambda y.\lambda x.UTILISER(x, y)\]
Après, nous appliquons la règle ``NP \textrightarrow\ BERT" pour avoir la réalisation sémantique : 
\[NP.sem = BERT\]
Ces deux dernière variables nous permet d'appliquer la règle ``VP \textrightarrow\ V\textsubscript{t} NP" pour avoir la réalisation sémantique :
\begin{align*}
 VP.sem & = V_t.sem(NP.sem) \\
        & = \textcolor{red}{\lambda y}.\lambda x.UTILISER(x, \textcolor{red}{y})(\textcolor{blue}{BERT})\\
        & = \lambda x.UTILISER(x, BERT)
\end{align*}
Finalement, nous pouvons appliquer la règle ``S \textrightarrow\ NP VP" pour avoir :
\begin{align*}
S.sem & = VP.sem(NP.sem) \\
       & = \textcolor{red}{\lambda x}.UTILISER(\textcolor{red}{x}, BERT)(\textcolor{blue}{KARIM})\\
       & = UTILISER(KARIM, BERT)
\end{align*}

\begin{figure}[ht]
	\centering
%	\begin{tabular}{ll}
%		\hgraphpage[0.35\textwidth]{sem-gram_.pdf} & 
		\hgraphpage[0.6\textwidth]{sem-arbre.pdf}
%	\end{tabular}
	\caption[Exemple d'une grammaire syntaxique-sémantique et une dérivation.]{Exemple d'une grammaire syntaxique-sémantique, ainsi que l'arbre de dérivation de la phrase ``\expword{Karim utilise BERT}" ; figure inspirée de \cite{2018-eisenstein}.}
	\label{fig:arbre-sem1}
\end{figure}

Maintenant, essayons d'analyser la phrase ``\expword{un étudiant utilise BERT}".
Nous pouvons la représenter en \ac{fol} comme ``\expword{$\exists x\ ETUDIANT(x) \wedge UTILISER(x, BERT)$}".
Les règles sémantiques pour prendre les quantificateurs en considération sont indiquées dans le tableau \ref{tab:regles-sem2}. 
Le quantificateur doit être ajouté lorsque nous rencontrons un déterminant (a, an) et donc nous aurons $\exists x$. 
Aussi, nous savons qu'avec un quantificateur, nous devons avoir un prédicat qui décrit le type de $x$, donc $\exists x P(x)$.
Ce prédicat est le nom qui suit le quantificateur ; donc, nous pouvons définir une $\lambda $-expression qui remplace $P$ par la réalisation sémantique du nom suivant, d'où $\lambda P.\exists x P(x)$.
Il faut aussi ajouter un ou plusieurs prédicats qui définissent la relation de $x$ avec les autres termes. 
Vu que nous puissions générer plusieurs prédicats avec une seule $\lambda $-expression, nous pouvons définir une seule $\lambda P.P(x)$.
$\lambda P$ doit être réduite avant $\lambda Q$ (le nom est plus proche au déterminant), donc $\lambda P.\lambda Q.\exists x\ P(x) \wedge Q(x)$. 
Dans ce cas : 
\[\lambda P.\lambda Q.\exists x\ P(x) \wedge Q(x)(CHAT) = \lambda Q.\exists x\ CHAT(x) \wedge Q(x)\]

\begin{table}[ht]
	\centering
	\begin{tabular}{lllllllll}
		\cline{1-4}\cline{6-9}\noalign{\vskip\doublerulesep
			\vskip-\arrayrulewidth}\cline{1-4}\cline{6-9}
		S  & \textrightarrow\ NP VP && NP.sem(VP.sem) &&
		DET & \textrightarrow\ chaque && $\lambda P.\lambda Q.\forall x (P(x) \Rightarrow Q(x))$ \\
		
		VP & \textrightarrow\ V\textsubscript{t} NP && V\textsubscript{t}.sem(NP.sem) &&
		V\textsubscript{t}  & \textrightarrow\ utilise && $\lambda P.\lambda x.P(\lambda y.UTILISER(x, y))$ \\
		
		VP & \textrightarrow\ V\textsubscript{i} && V\textsubscript{i}.sem &&
		V\textsubscript{i}  & \textrightarrow\ dort && $ \lambda $x.DORMIR(x) \\
		
		NP & \textrightarrow\ DET NN && DET.sem(NN.sem)  &&
		NN  & \textrightarrow\  étudiant && ETUDIANT \\
		
		NP & \textrightarrow\ NNP && $\lambda P.P(NNP.sem)$  &&
		NNP  & \textrightarrow\  Karim && KARIM \\
		
		DET & \textrightarrow\ un && $\lambda P.\lambda Q.\exists x\ P(x) \wedge Q(x)$  &&
		NNP  & \textrightarrow\  BERT && BERT \\
		\cline{1-4}\cline{6-9}\noalign{\vskip\doublerulesep
			\vskip-\arrayrulewidth}\cline{1-4}\cline{6-9}
	\end{tabular}
	\caption{Grammaire à contexte libre minimale avec les annotations sémantiques.}
	\label{tab:regles-sem2}
\end{table}

Supposons que le $NP$ précédent est celui généré par la racine ``S \textrightarrow NP VP". 
Si nous gardions la grammaire précédente (tableau \ref{tab:regles-sem1}), le contenu du syntagme verbale serait $\lambda x.UTILISER(x, BERT)$ et la sémantique de la phrase serait :
\begin{align*}
S.sem & = VP.sem(NP.sem) \\
& = \textcolor{red}{\lambda x}.UTILISER(\textcolor{red}{x}, BERT)(\textcolor{blue}{\lambda Q.\exists x\ ETUDIANT(x) \wedge Q(x)})\\
& = UTILISER(\lambda Q.\exists x\ ETUDIANT(x) \wedge Q(x), BERT)
\end{align*}
Cela n'est pas juste ; nous pouvons voir que ce soit toujours une $\lambda $-expression. 
Ce que nous voulons faire est de réduire $\lambda Q$ avec le contenu sémantique du syntagme verbale, et donc :
\begin{align*}
S.sem & = NP.sem(VP.sem) \\
& = \textcolor{red}{\lambda Q}.\exists x\ ETUDIANT(x) \wedge \textcolor{red}{Q}(x)(\textcolor{blue}{\lambda x.UTILISER(x, BERT)})\\
& = \exists x\ ETUDIANT(x) \wedge \textcolor{red}{\lambda x}.UTILISER(\textcolor{red}{x}, BERT))(x) \\
& = \exists x\ ETUDIANT(x) \wedge UTILISER(x, BERT)
\end{align*}

Lorsque nous voulons générer l'exemple du début (\expword{Karim utilise BERT}), nous devons appliquer ``NP.sem(VP.sem)". 
Mais, nous savons clairement que $NP.sem = KARIM$ n'est pas une $\lambda $-expression ; nous ne pouvons pas la réduire. 
La solution est d'appliquer ``VP.sem(NP.sem)" sans changer la règle sémantique ``NP.sem(VP.sem)". 
Nous devons, donc, ajouter une expression $\lambda P.P(NNP.sem)$ dans le syntagme nominal qui génère un nom propre. 
Dans notre cas, $NNP.sem = KARIM$ et donc :
\begin{align*}
S.sem & = NP.sem(VP.sem) \\
& = \textcolor{red}{\lambda P}.\textcolor{red}{P}(KARIM)(\textcolor{blue}{\lambda x.UTILISER(x, BERT)})\\
& = \textcolor{red}{\lambda x}.UTILISER(\textcolor{red}{x}, BERT))(\textcolor{blue}{KARIM}) \\
& = UTILISER(KARIM, BERT)
\end{align*}

Nous avons supposé que la réalisation sémantique du \keyword[S]{syntagme} verbal est $\lambda x.UTILISER(x, BERT)$. 
Nous allons essayer de calculer la réalisation avec la règle sémantique de $VP \rightarrow\ V\textsubscript{t} NP$ avant sa modification (tableau \ref{tab:regles-sem1}).
\begin{align*}
VP.sem & = V_t.sem(NP.sem )\\
& = \textcolor{red}{\lambda y}.\lambda x.UTILISER(x, \textcolor{red}{y})(\textcolor{blue}{\lambda P.P(BERT)})\\
& = \lambda x.UTILISER(x, \lambda P.P(BERT))
\end{align*}
Ce n'est pas le résultat voulu. 
Pour un verbe transitif, nous voulons résoudre le deuxième argument $y$ en premier. 
Donc, nous devons lui passer ``TALN" et pour le faire nous devons nous débarrasser de $\lambda P$. 
Dans ce cas, nous laissons $\lambda x$ à coté et nous essayons d'appliquer $\lambda P$ sur le reste. 
La règle sémantique sera $\lambda P.\lambda x.P(\lambda y.UTILISER(x, y))$, et donc :
\begin{align*}
VP.sem & = V_t.sem(NP.sem) \\
& = \textcolor{red}{\lambda P}.\lambda x.\textcolor{red}{P}(\lambda y.UTILISER(x, y))(\textcolor{blue}{\lambda P.P(BERT)}) \\
& = \lambda x.\textcolor{red}{\lambda P}.\textcolor{red}{P}(BERT)(\textcolor{blue}{\lambda y.UTILISER(x, y)}) \\
& = \lambda x.\textcolor{red}{\lambda y}.UTILISER(x, \textcolor{red}{y})(\textcolor{blue}{BERT}) \\
& = \lambda x.UTILISER(x, BERT) \\
\end{align*}

L'analyse sémantique de la phrase ``\expword{un étudiant utilise BERT}" est illustrée sous forme d'un arbre dans la figure \ref{fig:regles-sem2}.
Cette analyse se fait en parallèle avec l'analyse syntaxique comme l'analyse \keyword[C]{CKY}. 
Lorsqu'une règle syntaxique est appliquée, nous appliquons sa règle sémantique équivalente.
Nous avons vu que les grammaires des langages naturels sont plus complexes et donc non déterministes. 
\keyword[C]{CKY} probabiliste peut être utilisée pour résoudre le problème d'ambigüité.
Sinon, nous pouvons utiliser le sens généré afin de guider l'analyse. 
Donc, étant donné une phrase $w$ et une fonction de score $\Phi$ qui possède des paramètres $\theta$, la forme sémantique finale $\hat{z}$ est celle qui maximise cette fonction de score comme indiqué dans l'équation \ref{eq:sem-anal-max}.
\begin{equation}
\hat{z} = \arg\max_z \Phi(z|w, \theta)
\label{eq:sem-anal-max}
\end{equation}
La phrase $w$, étant une séquence, $\Phi$ peut être représentée comme une fonction séquentielle qui génère la représentation suivante sachant des caractéristiques comme le mot courant, les mots passés, leurs représentations, etc. 
Donc, afin de maximiser $\Phi$, nous devons tester plusieurs chemins d'analyse. 
Une des méthodes pour optimiser ce processus est d'utiliser \keyword{Beam Search}. 
L'annotation manuelle des représentations sémantiques est vraiment une tâche coûteuse.
Une autre méthode pour entraîner le modèle est en utilisant les dénotations. 
Par exemple, si la tâche de l'analyse sémantique a comme but d'avoir la représentation sémantique des questions, nous pouvons utiliser SQL comme représentation. 
La dénotation veut dire attribuer à chaque question une liste des résultats possibles à partir d'une base de donnée précise. 
Dans ce cas, lors de l'entraînement, nous n'allons pas tester si la requête SQL générée est correcte ; mais, nous allons tester le résultat de son exécution. 

\begin{figure}[ht]
	\centering
%	\begin{tabular}{ll}
%		\hgraphpage[0.3\textwidth]{sem-qgram_.pdf} & 
		\hgraphpage[0.8\textwidth]{sem-qarbre.pdf}
%	\end{tabular}
	\caption[Exemple d'une grammaire syntaxique-sémantique avec quantificateurs.]{Exemple d'une grammaire syntaxique-sémantique avec quantificateurs, ainsi que l'arbre de dérivation de la phrase ``\expword{un étudiant utilise BERT}" ; figure inspirée de \cite{2018-eisenstein}.}
	\label{fig:regles-sem2}
\end{figure}

Parmi les APIs qui nous permettent d'analyser des phrases sémantiquement, nous pouvons citer \keyword[N]{NLTK}\footnote{NLTK semantic parsing : \url{https://www.nltk.org/book/ch10.html} [visité le 2021-09-11]}. 
Dans le code suivant, le résultat est : \\
\begin{center}
	all z2.(dog(z2) -> exists z1.(bone(z1) \& give(angus,z1,z2)))
\end{center}

\begin{lstlisting}[language=Python, style=codeStyle]
from nltk import load_parser
parser = load_parser('grammars/book_grammars/simple-sem.fcfg', trace=0)
sentence = 'Angus gives a bone to every dog'
tokens = sentence.split()
for tree in parser.parse(tokens):
    print(tree.label()['SEM'])
\end{lstlisting}


%\begin{discussion}
\sectioni{Discussion}

La forme syntaxique ne porte pas le sens de la phrase ; elle sert à vérifier qu'une phrase est bien écrite selon la langue en question. 
Les rôles sémantiques des différents éléments d'une phrase peuvent être déduits à partir des fonctions syntaxiques. 
Par exemple, nous pouvons appliquer une analyse syntaxique et faire une correspondance avec les rôles sémantiques. 
Un sujet du verbe peut être considéré comme un agent. 
Mais, cela n'est pas toujours le cas ; dans la forme passive, le sujet est un patient. 
Donc, la transition du niveau syntaxique vers le niveau sémantique n'est pas aussi simple que ça. 
Il existe plusieurs projets qui visent à faciliter cette tâche comme FrameNet et PropBank. 
Ils représentent les phrases sous forme des cadres où l'évènement est l'élément central. 

Représenter une phrase comme cadres est utile dans des tâches de compréhension du langage. 
Mais, des fois, cette représentation n'est pas adéquate pour certaines tâches. 
Dans le raisonnement par machine, nous voulons avoir une machine qui peut appliquer des déductions. 
Par exemple, nous pouvons trouver des contradictions entre les phrases d'un article de presse. 
Une des représentations qui peuvent nous permettre cela est la logique propositionnelle et plus précisément la logique du premier ordre. 
Afin de générer une telle représentation, nous pouvons utiliser une grammaire constituante et affecter à chaque règle syntaxique une règle sémantique.
La forme sémantique n'est pas toujours une expression de la logique du premier ordre. 
Elle pourrait être une requête SQL, si nous voulions implémenter un système de Question/réponse. 
Aussi, elle pourrait être une commande, si nous voulions implémenter un assistant personnel intelligent comme Alexa, Cortana ou Siri.
%\end{discussion}

\sectioni{Ressources supplémentaires}

\subsubsection*{Exercices}

\begin{enumerate}
	\item Voici deux phrases 
	
	\begin{tabular}{|l|}
		\hline 
		\ul{Chaque étudiant} prépare \ul{un rapport} avec \ul{\LaTeX} \\
		Si \ul{un étudiant} est inscrit à \ul{l'ESI} donc \ul{il} étudie \ul{l'informatique}\\
		\hline 
	\end{tabular}

	\begin{enumerate}
		\item Pour chaque expression soulignée, indiquer le rôle thématique en utilisant le tableau vu en cours.
		\item Supposons que nous avons utilisé un LSTM pour estimer ces rôles. 
		Écrire le résultat de chaque phrase en utilisant la représentation IOB.
		\item En utilisant la version française de FrameNet (\url{http://asfalda.linguist.univ-paris-diderot.fr/luIndex.xml} [visité le 2022-05-09]), indiquer les cadres sémantiques activées pour chaque phrase.
		\item En utilisant la version française de PropBank (\url{https://alanakbik.github.io/UniversalPropositions_French/} [visité le 2022-05-09]), indiquer les prédicats activés.
		\item Annoter les deux phrases en se basant sur les arguments de chaque prédicat.
		\item Proposer une grammaire hors contexte pour générer ces phrases.
		\item Représenter les deux phrases en logique du premier ordre où le domaine fournit les prédicats suivants : 
		Rapport(x) ; Etudiant(x) ; Preparer(x, y) ; Préparer-Avec(x) ; Inscrit-A(x, y). 
		Il fournit, aussi, les constantes suivantes : ESI ; LATEX.
		\item Enrichir la grammaire précédente par des règles sémantiques afin de générer ces représentations.
		\item Dessiner l'arbre sémantique de chaque phrase.
		\item Maintenant, nous voulons utiliser une représentation néo-Davidsonienne. 
		Le domaine, dans ce cas, fournit les prédicats suivants : 
		Etudiant(x) ; Preparer(e) ; Preparer-Agent(e, x) ; Preparer-Theme(e, x) ; Preparer-Instrument(e, x) ; Inscrire-Location(e, x).
		Il fournit, aussi, les constantes suivantes : ESI ; LATEX.
		\item Enrichir la grammaire précédente par des règles sémantiques afin de générer ces représentations.
		\item Dessiner l'arbre sémantique de chaque phrase.
	\end{enumerate}

	
\end{enumerate}

\subsubsection*{Tutoriels}

Les tutoriels sont accessibles via le répertoire Github.
Nous présentons deux outils en python : NLTK et amrlib.
NLTK nous permet d'exploiter les trois bases : FrameNet, PropBank et VerbNet.
Nous présentons la logique propositionnelle sur NLTK : création des expressions et leurs preuves ainsi que la logique du premier ordre.
Ensuite, nous testons l'analyse sémantique avec les règles syntaxiques et les expressions lambda présentées dans le cours comme exemple.
L'autre tutoriel concerne l'utilisation de l'outil amrlib avec spaCy pour générer la représentation AMR d'un texte.

%\subsubsection*{TP : Analyse syntaxique CKY}

%\subsubsection*{Lab}

%=====================================================================
\ifx\wholebook\relax\else
% \cleardoublepage
% \bibliographystyle{../use/ESIbib}
% \bibliography{../bib/RATstat}
	\end{document}
\fi
%=====================================================================
